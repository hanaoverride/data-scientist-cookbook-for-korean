# 6. 특이값 분해(SVD): 모든 행렬을 분해하는 궁극의 도구

## 목차
- [6. 특이값 분해(SVD): 모든 행렬을 분해하는 궁극의 도구](#6-특이값-분해svd-모든-행렬을-분해하는-궁극의-도구)
  - [목차](#목차)
  - [1. SVD의 직관적 의미: 모든 변환은 '회전-스케일링-회전'이다](#1-svd의-직관적-의미-모든-변환은-회전-스케일링-회전이다)
    - [`A = UΣVᵀ`: SVD의 세 가지 구성 요소](#a--uσvᵀ-svd의-세-가지-구성-요소)
  - [2. SVD와 고유값 분해의 관계](#2-svd와-고유값-분해의-관계)
  - [3. SVD의 가장 강력한 응용: 차원 축소와 데이터 압축](#3-svd의-가장-강력한-응용-차원-축소와-데이터-압축)
    - [Full SVD vs. Truncated SVD](#full-svd-vs-truncated-svd)
    - [실전 예제: 이미지 압축으로 SVD 위력 확인하기](#실전-예제-이미지-압축으로-svd-위력-확인하기)

---

## 1. SVD의 직관적 의미: 모든 변환은 '회전-스케일링-회전'이다

SVD는 아무리 복잡해 보이는 행렬 변환 `A`라도, 결국 세 단계의 간단한 기하학적 변환의 조합으로 분해할 수 있다고 말합니다.

1.  **입력 공간에서의 회전 (Vᵀ)** : 먼저 입력 공간을 적절히 회전시킵니다.
2.  **축 방향으로의 스케일링 (Σ)** : 회전된 공간의 각 축을 특정 비율로 늘리거나 줄입니다.
3.  **출력 공간에서의 회전 (U)** : 스케일링된 공간을 출력 공간에 맞게 다시 회전시킵니다.

### `A = UΣVᵀ`: SVD의 세 가지 구성 요소

- **`A` (m x n 행렬)** : 우리가 분해하려는 원본 행렬 (선형변환)

- **`U` (m x m 직교 행렬)** : **출력 공간(Column Space)의 직교기저(축)**  들을 담고 있습니다. 이 축들을 **좌특이벡터(Left Singular Vectors)**  라고 부릅니다.
- **`Σ` (m x n 대각 행렬)** : 대각선에 **특이값(Singular Values)**  `σ` 들이 큰 순서대로 정렬되어 있습니다. 각 특이값은 `V`의 축이 `U`의 축으로 변환될 때 **얼마나 중요한지(스케일이 얼마나 변하는지)**  를 나타냅니다.
- **`Vᵀ` (n x n 직교 행렬)** : **입력 공간(Row Space)의 직교기저(축)**  들을 담고 있는 `V`를 전치한 행렬입니다. `V`의 축들을 **우특이벡터(Right Singular Vectors)**  라고 부릅니다.

> **핵심**: SVD는 복잡한 행렬 `A`를, **입력 공간의 주요 축(`V`)** , **출력 공간의 주요 축(`U`)** , 그리고 **두 축을 연결하는 강도(`Σ`)**  라는 세 가지 정보로 완벽하게 분해합니다.

## 2. SVD와 고유값 분해의 관계

SVD는 고유값 분해의 '일반화된 버전'입니다.
- **고유값 분해**: `A = PDP⁻¹` (A가 정방행렬일 때만 가능)
- **SVD**: `A = UΣVᵀ` (모든 행렬에 가능)

만약 행렬 `A`가 대칭 행렬이라면, SVD와 고유값 분해는 거의 같아집니다 (`U`와 `V`가 같아지고, 특이값은 고유값의 절대값과 같아짐).

SVD의 각 요소는 `A`와 `Aᵀ`를 곱한 대칭 행렬의 고유값 분해를 통해 찾을 수 있습니다.
- `AᵀA`의 고유벡터가 `V`를 구성합니다.
- `AAᵀ`의 고유벡터가 `U`를 구성합니다.
- `AᵀA` 또는 `AAᵀ`의 고유값의 제곱근이 바로 특이값 `σ` 입니다.

## 3. SVD의 가장 강력한 응용: 차원 축소와 데이터 압축

SVD의 진정한 힘은, **중요한 정보(큰 특이값)와 중요하지 않은 정보(작은 특이값)를 분리**해준다는 데 있습니다.

특이값 `σ`는 각 축의 '중요도'를 의미하므로, 값이 큰 상위 몇 개의 특이값과 그에 해당하는 `U`, `V`의 벡터들만 사용해도 원본 행렬을 매우 근사하게 복원할 수 있습니다.

### Full SVD vs. Truncated SVD

- **Full SVD**: `U`, `Σ`, `V`를 모두 사용하여 행렬 `A`를 완벽하게 복원합니다.
- **Truncated SVD**: 상위 `k`개의 특이값과 그에 해당하는 벡터들만 사용하여 행렬 `A`를 근사합니다. `A ≈ U_k Σ_k V_kᵀ`. 이것이 바로 **차원 축소**와 **데이터 압축**의 핵심 원리입니다.

### 실전 예제: 이미지 압축으로 SVD 위력 확인하기

이미지 또한 하나의 큰 행렬입니다. 이 이미지 행렬에 SVD를 적용하여, 적은 수의 특이값만으로 이미지를 복원해 봅시다.

```python
import numpy as np
import matplotlib.pyplot as plt
from skimage import data
from skimage.color import rgb2gray
from skimage.transform import resize

# 예제 이미지 로드 (흑백으로 변환)
image = rgb2gray(data.astronaut())
image = resize(image, (256, 256))

# SVD 수행
U, S, VT = np.linalg.svd(image, full_matrices=False)

# 복원에 사용할 특이값 개수 설정
k_values = [5, 20, 50]

plt.figure(figsize=(15, 5))

# 원본 이미지
plt.subplot(1, len(k_values) + 1, 1)
plt.title("Original")
plt.imshow(image, cmap='gray')
plt.axis('off')

# Truncated SVD로 이미지 복원 및 시각화
for i, k in enumerate(k_values):
    # 상위 k개의 특이값과 벡터들로 이미지 근사
    approx_image = U[:, :k] @ np.diag(S[:k]) @ VT[:k, :]
    
    plt.subplot(1, len(k_values) + 1, i + 2)
    plt.title(f"k = {k}")
    plt.imshow(approx_image, cmap='gray')
    plt.axis('off')

plt.show()
```
> **인사이트**: 단 50개의 특이값만 사용해도 원본 이미지의 모습을 거의 알아볼 수 있습니다. 원본 이미지는 `256 * 256 = 65536`개의 숫자로 이루어져 있지만, `k=50`으로 압축하면 `50 * (256 + 1 + 256) = 25650`개의 숫자만으로 비슷한 이미지를 표현할 수 있습니다. 이것이 SVD를 이용한 데이터 압축의 힘입니다.