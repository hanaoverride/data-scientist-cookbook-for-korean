# 5. 인공지능 모델 성능 향상을 위한 핵심 딥러닝 기법

## 목차 📑

### 1. 인공신경망의 학습과 추론
- [1.1 인공신경망의 학습과 추론 개요](#인공신경망의-학습과-추론-개요-) 🧠
- [1.2 학습·테스트·추론 과정](#학습테스트추론-과정-) 🔄
- [1.3 학습과 추론의 비교](#학습과-추론의-비교-) ⚖️
- [1.4 그래픽카드의 역할](#그래픽카드의-역할-) 💻

### 2. 학습 조기 종료(Early Stopping)
- [2.1 과적합 문제](#과적합-문제-) 🚨
- [2.2 학습/검증 손실 그래프](#학습검증-손실-그래프-) 📉
- [2.3 조기 종료 원리](#조기-종료-원리-) ⏹️

### 3. 데이터 증강
- [3.1 데이터셋 크기와 품질](#데이터셋-크기와-품질-) 📊
- [3.2 불충분·불균형 데이터셋](#불충분불균형-데이터셋-) ⚠️
- [3.3 데이터 증강 기법](#데이터-증강-기법-) 🧬
- [3.4 이미지/연속형 데이터 증강](#이미지연속형-데이터-증강-) 🖼️

### 4. 가중치 규제
- [4.1 편향-분산 트레이드오프](#편향-분산-트레이드오프-) 📈
- [4.2 모델 규제의 원리](#모델-규제의-원리-) 🏋️
- [4.3 가중치 규제 방식](#가중치-규제-방식-) 🧮
- [4.4 규제 강도의 영향](#규제-강도의-영향-) ⚙️

### 5. 드롭아웃
- [5.1 드롭아웃 개념](#드롭아웃-개념-) 🎲
- [5.2 드롭아웃의 원리](#드롭아웃의-원리-) 🧩
- [5.3 드롭아웃 적용 효과](#드롭아웃-적용-효과-) 🏆

### 6. AutoML
- [6.1 파라미터 튜닝의 중요성](#파라미터-튜닝의-중요성-) 🔧
- [6.2 AutoML 개요](#automl-개요-) 🤖
- [6.3 AutoML 서비스와 활용](#automl-서비스와-활용-) 🌐

### 7. 기타 딥러닝 심화 기법들
- [7.1 Residual Connections(ResNet)](#residual-connectionsresnet-) 🔗
- [7.2 순환신경망(RNN)](#순환신경망rnn-) 🔄
- [7.3 합성곱신경망(CNN)](#합성곱신경망cnn-) 🖼️
- [7.4 트랜스포머(Transformer)](#트랜스포머transformer-) 🧠

---

## 인공신경망의 학습과 추론 개요 🧠

**설명**  
인공신경망은 데이터셋에서 **일반적인 패턴**을 학습하고, 이를 바탕으로 새로운 데이터에 대해 **추론**을 수행하는 모델이다. 학습은 데이터의 규칙을 찾아내는 과정이며, 추론은 학습된 모델을 활용해 실제 예측을 수행하는 단계이다.

**예시**

```python
# 새로운 데이터셋에서 패턴을 학습하고 예측하는 예시
import torch
import torch.nn as nn

# 임의의 데이터 생성
inputs = torch.tensor([[1.0, 2.0], [2.0, 1.0], [1.5, 1.5]])
targets = torch.tensor([[3.0], [3.0], [3.0]])

# 간단한 신경망 모델 정의
model = nn.Sequential(
    nn.Linear(2, 4),
    nn.ReLU(),
    nn.Linear(4, 1)
)

# 학습 과정 생략, 예측만 수행
with torch.no_grad():
    predictions = model(inputs)
print(predictions)
```

**주의사항**  
- 학습 과정에서 데이터의 일반적 특성을 충분히 반영해야 한다.
- 추론 단계에서는 학습에 사용되지 않은 데이터로 모델의 성능을 평가해야 한다.

---

## 학습·테스트·추론 과정 🔄

**설명**  
인공신경망의 학습은 **배치 단위 데이터**를 순차적으로 처리하며, 각 배치마다 순전파와 역전파를 반복한다. 학습이 끝나면 **테스트 데이터**로 모델의 일반화 능력을 평가하고, 실제 서비스에서는 추론만 수행한다.

**예시**

```python
# 학습, 검증, 추론 데이터 분리 예시
from sklearn.model_selection import train_test_split

data = [[i, i+1] for i in range(100)]
labels = [i*2 for i in range(100)]

train_x, temp_x, train_y, temp_y = train_test_split(data, labels, test_size=0.4)
val_x, test_x, val_y, test_y = train_test_split(temp_x, temp_y, test_size=0.5)

print(f"학습 데이터 크기: {len(train_x)}")
print(f"검증 데이터 크기: {len(val_x)}")
print(f"테스트 데이터 크기: {len(test_x)}")
```

**주의사항**  
- 학습 데이터의 비율이 가장 크며, 검증 데이터는 과적합 방지에 사용된다.
- 추론 단계에서는 기울기 계산이 필요 없으므로 연산이 빠르다.

---

## 학습과 추론의 비교 ⚖️

**설명**  
학습 단계에서는 데이터 전처리, 순전파, 손실 계산, 역전파, 파라미터 최적화, 검증 등 다양한 과정이 포함된다. 반면, 추론 단계에서는 전처리와 순전파만 수행하며, 역전파 및 파라미터 업데이트는 생략된다.

| 단계 | 학습 | 추론 |
|------|------|------|
| 데이터 | 배치 단위 | 1개 또는 소규모 |
| 순전파 | O | O |
| 손실 계산 | O | X |
| 역전파 | O | X |
| 파라미터 업데이트 | O | X |
| 검증 | O | X |

**예시**

```python
# 학습과 추론 단계 구분 예시
def train_step(model, x, y, optimizer, loss_fn):
    model.train()
    optimizer.zero_grad()
    output = model(x)
    loss = loss_fn(output, y)
    loss.backward()
    optimizer.step()
    return loss.item()

def inference_step(model, x):
    model.eval()
    with torch.no_grad():
        return model(x)
```

**주의사항**  
- 추론 시에는 학습과 동일한 전처리 과정을 적용해야 한다.
- 학습 단계에서는 연산량이 많고, 추론 단계는 상대적으로 빠르다.

---

## 그래픽카드의 역할 💻

**설명**  
**그래픽카드(GPU)** 는 인공신경망의 병렬 연산에 최적화되어 있어, 대량의 데이터를 빠르게 처리할 수 있다. 특히, 대규모 신경망 모델의 학습 및 실시간 추론에 필수적이다.

**예시**

```python
# GPU 사용 여부 확인 및 데이터 이동 예시
import torch

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"사용 중인 디바이스: {device}")

# 모델과 데이터를 GPU로 이동
model = nn.Linear(2, 1).to(device)
sample = torch.tensor([[1.0, 2.0]]).to(device)
output = model(sample)
print(output)
```

**주의사항**  
- GPU와 CPU 간 데이터 이동 시 병목 현상이 발생할 수 있다.
- 모든 연산이 GPU에서 더 빠른 것은 아니므로, 작업 특성에 따라 적절히 선택해야 한다.

---

## 과적합 문제 🚨

**설명**  
**과적합(Overfitting)** 은 모델이 학습 데이터에 지나치게 적합하여, 새로운 데이터에 대한 예측 성능이 저하되는 현상이다. 반복적인 최적화로 인해 발생하며, 일반화 능력이 떨어진다.

**예시**

```python
# 과적합 예시: 훈련 데이터에만 잘 맞는 모델
import numpy as np
import matplotlib.pyplot as plt

x_train = np.linspace(0, 1, 10)
y_train = np.sin(2 * np.pi * x_train) + np.random.normal(0, 0.1, 10)
x_test = np.linspace(0, 1, 100)
y_test = np.sin(2 * np.pi * x_test)

# 고차 다항식 피팅(과적합)
coeffs = np.polyfit(x_train, y_train, 9)
y_pred = np.polyval(coeffs, x_test)

plt.plot(x_test, y_test, label='실제 함수')
plt.plot(x_test, y_pred, label='과적합 모델')
plt.scatter(x_train, y_train, color='red', label='학습 데이터')
plt.legend()
plt.show()
```

**주의사항**  
- 과적합된 모델은 새로운 데이터에 대해 신뢰할 수 없는 예측을 한다.
- 검증 데이터셋을 활용하여 과적합 여부를 반드시 확인해야 한다.

---

## 학습/검증 손실 그래프 📉

**설명**  
학습 과정에서 **학습 손실**과 **검증 손실**을 동시에 모니터링하면, 모델의 과적합 여부를 쉽게 파악할 수 있다. 학습 손실은 계속 감소하지만, 검증 손실이 증가하기 시작하면 과적합이 발생한 것이다.

**예시**

```python
# 임의의 손실 곡선 시뮬레이션
import matplotlib.pyplot as plt

epochs = np.arange(1, 101)
train_loss = np.exp(-epochs/30) + 0.02 * np.random.rand(100)
val_loss = np.exp(-epochs/30) + 0.05 * (epochs > 60)

plt.plot(epochs, train_loss, label='학습 손실')
plt.plot(epochs, val_loss, label='검증 손실')
plt.xlabel('에폭')
plt.ylabel('손실')
plt.legend()
plt.title('학습/검증 손실 곡선')
plt.show()
```

**주의사항**  
- 검증 손실이 최소가 되는 시점을 기준으로 모델 파라미터를 저장하는 것이 바람직하다.
- 검증 손실이 일시적으로 증가할 수 있으므로, **patience**(여유 에폭)를 두고 조기 종료를 적용한다.

---

## 조기 종료 원리 ⏹️

**설명**  
**조기 종료(Early Stopping)** 는 검증 손실이 더 이상 개선되지 않을 때 학습을 중단하는 기법이다. 이를 통해 과적합을 방지하고, 최적의 모델을 확보할 수 있다.

**예시**

```python
# 조기 종료 구현 예시
best_val_loss = float('inf')
patience = 5
wait = 0

for epoch in range(100):
    # 가상의 손실값
    val_loss = np.random.uniform(0.1, 0.5) + max(0, (epoch-60)*0.01)
    if val_loss < best_val_loss:
        best_val_loss = val_loss
        wait = 0
        # 모델 저장 코드 위치
    else:
        wait += 1
        if wait >= patience:
            print(f"{epoch+1}번째 에폭에서 조기 종료")
            break
```

**주의사항**  
- patience 값을 너무 작게 설정하면 최적점에 도달하기 전에 학습이 중단될 수 있다.
- 조기 종료 시, 검증 손실이 최소였던 모델 파라미터를 반드시 저장해야 한다.

---

## 데이터셋 크기와 품질 📊

**설명**  
**데이터셋의 크기와 품질**은 인공신경망의 성능에 직접적인 영향을 미친다. 대규모 데이터와 다양한 상황을 반영한 데이터가 필요하며, 데이터 라벨링 자원이 부족하거나 현실적으로 데이터 확보가 어려운 경우가 많다.

**예시**

```python
# 데이터셋 크기와 품질 확인 예시
import pandas as pd

data = pd.DataFrame({
    '특성1': [1, 2, 3, 4, 5],
    '특성2': [5, 4, 3, 2, 1],
    '라벨': ['A', 'A', 'B', 'B', 'B']
})
print(f"데이터셋 크기: {data.shape}")
print(f"라벨 분포:\n{data['라벨'].value_counts()}")
```

**주의사항**  
- 데이터셋이 작거나 한쪽 라벨에 편중되어 있으면 모델의 일반화 성능이 저하된다.
- 데이터 라벨링 품질이 낮으면 학습 결과가 왜곡될 수 있다.

---

## 불충분·불균형 데이터셋 ⚠️

**설명**  
현실적으로 데이터셋의 크기가 충분하지 않거나, 각 클래스별 데이터 수가 불균형한 경우가 많다. 인공신경망은 다수 클래스에만 집중하여 소수 클래스의 예측을 포기하는 경향이 있다.

**예시**

```python
# 클래스 불균형 예시
import numpy as np

labels = np.array(['X']*90 + ['Y']*10)
unique, counts = np.unique(labels, return_counts=True)
print(dict(zip(unique, counts)))
```

**주의사항**  
- 클래스 불균형은 모델이 소수 클래스를 무시하게 만들 수 있다.
- 데이터 증강이나 클래스 가중치 조정 등 추가적인 처리가 필요하다.

---

## 데이터 증강 기법 🧬

**설명**  
**데이터 증강(Data Augmentation)** 은 기존 데이터를 변형하여 데이터의 양과 다양성을 인위적으로 늘리는 방법이다. 이는 과적합을 방지하고, 모델의 일반화 성능을 높이는 데 효과적이다.

**예시**

```python
# 이미지 데이터 증강 예시 (수평 뒤집기, 회전 등)
from torchvision import transforms
from PIL import Image

transform = transforms.Compose([
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(20)
])

img = Image.new('RGB', (64, 64), color='gray')
aug_img = transform(img)
aug_img.show()
```

**주의사항**  
- 데이터 증강을 과도하게 적용하면 실제와 동떨어진 데이터가 생성될 수 있다.
- 증강은 주로 데이터 로더나 입력층에서 적용한다.

---

## 이미지/연속형 데이터 증강 🖼️

**설명**  
이미지 데이터는 회전, 이동, 색상 변화 등 다양한 증강 기법이 적용 가능하다. 연속형(시계열) 데이터의 경우, 노이즈 추가, 시간 왜곡 등 특화된 증강 방법이 사용된다.

**예시**

```python
# 연속형 데이터 증강 예시: 노이즈 추가
import numpy as np
import matplotlib.pyplot as plt

signal = np.sin(np.linspace(0, 2*np.pi, 100))
aug_signal = signal + np.random.normal(0, 0.05, 100)

plt.plot(signal, label='원본')
plt.plot(aug_signal, label='증강(노이즈 추가)')
plt.legend()
plt.show()
```

**주의사항**  
- 증강 기법은 데이터의 특성에 맞게 선택해야 한다.
- 증강 데이터가 실제 상황을 반영하는지 항상 검증해야 한다.

---

## 편향-분산 트레이드오프 📈

**설명**  
**편향-분산 트레이드오프(Bias-Variance Tradeoff)** 는 모델의 예측 오차를 최소화하기 위해 편향과 분산을 동시에 고려해야 함을 의미한다. 과적합된 모델은 편향이 낮고 분산이 높으며, 과소적합된 모델은 그 반대이다.

**예시**

```python
# 편향-분산 트레이드오프 시각화 예시
import numpy as np
import matplotlib.pyplot as plt

x = np.linspace(-1, 1, 100)
y_true = x**2
y_high_bias = 0.5 * x + 0.2
y_high_var = x**2 + np.random.normal(0, 0.2, 100)

plt.plot(x, y_true, label='정답')
plt.plot(x, y_high_bias, label='높은 편향')
plt.plot(x, y_high_var, label='높은 분산')
plt.legend()
plt.show()
```

**주의사항**  
- 편향과 분산의 균형을 맞추는 것이 중요하다.
- 규제 기법을 통해 분산을 줄일 수 있으나, 편향이 너무 커지지 않도록 주의해야 한다.

---

## 모델 규제의 원리 🏋️

**설명**  
**모델 규제(Regularization)** 는 학습 과정에서 모델의 복잡도를 제한하여 과적합을 방지하는 방법이다. 일반적으로 손실 함수에 규제 항을 추가하여, 파라미터의 크기를 제어한다.

**예시**

```python
# L2 규제(릿지) 적용 예시
import torch
import torch.nn as nn

model = nn.Linear(3, 1)
l2_lambda = 0.01
criterion = nn.MSELoss()

def loss_with_l2(output, target, model, l2_lambda):
    mse = criterion(output, target)
    l2_norm = sum(torch.norm(param) for param in model.parameters())
    return mse + l2_lambda * l2_norm

# 사용 예시 생략
```

**주의사항**  
- 규제 항의 계수(λ)는 실험적으로 최적값을 찾아야 한다.
- 규제 강도가 너무 크면 학습이 제대로 이루어지지 않을 수 있다.

---

## 가중치 규제 방식 🧮

**설명**  
가중치 규제는 **가중치의 크기**에 패널티를 부여하는 방식이다. 대표적으로 L2 규제(릿지)가 있으며, 손실 함수에 가중치 제곱합을 추가한다.

**예시**

```python
# L2 규제 손실 함수 예시
def l2_regularized_loss(y_pred, y_true, model, l2_coeff):
    mse = ((y_pred - y_true) ** 2).mean()
    l2_penalty = l2_coeff * sum((p ** 2).sum() for p in model.parameters())
    return mse + l2_penalty
```

**주의사항**  
- L1 규제(라쏘)는 가중치의 절댓값 합을 사용하며, 일부 파라미터를 0으로 만들어 특성 선택 효과가 있다.
- L2 규제는 모든 파라미터를 작게 만드는 경향이 있다.

---

## 규제 강도의 영향 ⚙️

**설명**  
규제 계수(λ)가 너무 작으면 과적합이 발생하고, 너무 크면 과소적합이 발생한다. 적절한 규제 강도를 찾는 것이 중요하다.

**예시**

```python
# 규제 강도에 따른 모델 성능 비교
lambdas = [0, 0.001, 0.01, 1]
for l2 in lambdas:
    print(f"L2 규제 계수: {l2} -> 성능 평가(가상)")
    # 실제 학습 및 평가 코드 생략
```

**주의사항**  
- 규제 계수는 교차 검증 등으로 최적값을 탐색해야 한다.
- 데이터와 모델 구조에 따라 최적의 λ 값이 달라진다.

---

## 드롭아웃 개념 🎲

**설명**  
**드롭아웃(Dropout)** 은 학습 중에 일부 뉴런을 확률적으로 비활성화하여, 신경망이 특정 뉴런에 과도하게 의존하지 않도록 하는 규제 기법이다. 주로 깊은 신경망에서 과적합을 방지하는 데 사용된다.

**예시**

```python
# 드롭아웃 레이어 적용 예시
import torch.nn as nn

model = nn.Sequential(
    nn.Linear(8, 16),
    nn.ReLU(),
    nn.Dropout(p=0.4),
    nn.Linear(16, 4)
)
```

**주의사항**  
- 학습 시에만 드롭아웃이 활성화되며, 추론 시에는 비활성화된다.
- 드롭아웃 확률(p)은 0.2~0.5 범위에서 실험적으로 결정한다.

---

## 드롭아웃의 원리 🧩

**설명**  
드롭아웃은 각 학습 반복마다 일부 뉴런의 출력을 0으로 만들어, 신경망이 부분적인 정보만으로도 예측할 수 있도록 훈련한다. 이를 통해 모델이 데이터에 과도하게 적합되는 것을 방지한다.

**예시**

```python
# 드롭아웃 동작 시뮬레이션
import numpy as np

layer_output = np.array([0.8, 0.6, 0.9, 0.4])
dropout_mask = np.random.binomial(1, 0.5, size=layer_output.shape)
output_after_dropout = layer_output * dropout_mask
print(f"드롭아웃 적용 결과: {output_after_dropout}")
```

**주의사항**  
- 드롭아웃을 적용하면 학습 속도가 느려질 수 있으나, 일반화 성능이 향상된다.
- 드롭아웃 확률이 너무 높으면 학습이 어려워질 수 있다.

---

## 드롭아웃 적용 효과 🏆

**설명**  
드롭아웃이 적용된 모델은 더 일반적인 특성(피처)을 학습하며, 과적합이 줄어든다. 예를 들어, 손글씨 데이터 분류에서 드롭아웃을 적용하면 다양한 필체에 강인한 모델이 만들어진다.

**예시**

```python
# 드롭아웃 적용 전후 성능 비교(가상)
acc_without_dropout = 0.98
acc_with_dropout = 0.96
print(f"드롭아웃 미적용: {acc_without_dropout}, 드롭아웃 적용: {acc_with_dropout}")
```

**주의사항**  
- 드롭아웃 적용 시, 학습 정확도는 약간 낮아질 수 있으나, 테스트 데이터에 대한 성능은 더 높아질 수 있다.

---

## 파라미터 튜닝의 중요성 🔧

**설명**  
인공신경망의 성능은 **은닉층 개수**, **뉴런 수**, **학습률**, **배치 크기**, **드롭아웃 확률**, **가중치 규제 계수**, **옵티마이저**, **활성화 함수** 등 다양한 파라미터에 의해 크게 좌우된다. 최적의 파라미터 조합을 찾는 과정이 필수적이다.

**예시**

```python
# 파라미터 튜닝 예시
params = {
    'hidden_layers': 3,
    'neurons_per_layer': 64,
    'learning_rate': 0.005,
    'batch_size': 32,
    'dropout_rate': 0.3,
    'weight_decay': 0.0005,
    'optimizer': 'adam',
    'activation': 'relu'
}
print(params)
```

**주의사항**  
- 파라미터 조합에 따라 모델 성능이 크게 달라진다.
- 수동 튜닝은 시간이 오래 걸리므로 자동화 도구를 활용하는 것이 효율적이다.

---

## AutoML 개요 🤖

**설명**  
**AutoML(Automated Machine Learning)** 은 데이터에 가장 적합한 모델과 파라미터 조합을 자동으로 탐색하고, 최적의 모델을 선정·배포하는 기술이다. 하이퍼파라미터 튜닝, 모델 구조 탐색, 성능 평가 등이 자동화되어 있다.

**예시**

```python
# AutoML 라이브러리 사용 예시 (예시용 코드, 실제 라이브러리 사용법과 다를 수 있음)
from sklearn.datasets import load_iris
from autosklearn.classification import AutoSklearnClassifier

X, y = load_iris(return_X_y=True)
automl = AutoSklearnClassifier(time_left_for_this_task=60)
automl.fit(X, y)
print(automl.show_models())
```

**주의사항**  
- AutoML은 도메인 지식이 부족한 경우에도 빠르게 성능을 높일 수 있으나, 복잡한 문제에서는 한계가 있다.
- 자동화된 모델이 항상 최적의 해답을 제공하는 것은 아니다.

---

## AutoML 서비스와 활용 🌐

**설명**  
최근에는 **WandB**, **Google Cloud AutoML** 등 다양한 AutoML 서비스가 제공되어, 실시간 시각화, 하이퍼파라미터 탐색, 성능 분석 등을 지원한다. 그리드 탐색, 베이지안 최적화 등 다양한 탐색 기법이 활용된다.

**예시**

```python
# WandB Sweep 설정 예시 (실제 사용법과 다를 수 있음)
import wandb

sweep_config = {
    'method': 'bayes',
    'parameters': {
        'learning_rate': {'min': 0.0001, 'max': 0.01},
        'batch_size': {'values': [16, 32, 64]}
    }
}
sweep_id = wandb.sweep(sweep_config, project="example_project")
```

**주의사항**  
- AutoML 서비스는 무료와 유료가 혼재되어 있으므로, 사용 목적에 맞게 선택해야 한다.
- 자동화된 탐색 결과를 해석하고, 도메인 지식과 결합하여 최종 모델을 선정하는 것이 중요하다.

---

## Residual Connections(ResNet) 🔗

**설명**  
**Residual Connection**은 각 레이어의 출력을 다음 레이어의 입력에 직접 더하는 **Skip Connection** 구조를 의미한다. 이는 신경망이 깊어질 때 발생하는 **기울기 소실** 문제를 해결하며, 현대 딥러닝 모델의 핵심 구성 요소이다.

**예시**

```python
# Residual Block 예시
import torch.nn as nn

class ResidualBlock(nn.Module):
    def __init__(self, dim):
        super().__init__()
        self.layer = nn.Sequential(
            nn.Linear(dim, dim),
            nn.ReLU(),
            nn.Linear(dim, dim)
        )
    def forward(self, x):
        return x + self.layer(x)
```

**주의사항**  
- Residual 구조는 매우 깊은 네트워크에서 학습 안정성을 높인다.
- 입력과 출력의 차원이 일치해야 Skip Connection이 가능하다.

---

## 순환신경망(RNN) 🔄

**설명**  
**순환신경망(RNN)** 은 시계열 데이터나 문자열 등 순차적 정보를 처리하는 데 적합한 구조이다. 과거의 정보를 내부 상태에 저장하여, 다음 예측에 활용한다.

**예시**

```python
# RNN 셀 동작 예시
import torch.nn as nn

rnn = nn.RNN(input_size=5, hidden_size=8, batch_first=True)
sequence = torch.randn(2, 10, 5)  # (batch, seq_len, input_size)
output, hidden = rnn(sequence)
print(output.shape)
```

**주의사항**  
- RNN은 긴 시퀀스에서 기울기 소실 문제가 발생할 수 있으므로, LSTM이나 GRU 등 개선된 구조가 자주 사용된다.
- 입력 시퀀스의 길이에 따라 파라미터 공유가 이루어진다.

---

## 합성곱신경망(CNN) 🖼️

**설명**  
**합성곱신경망(CNN)** 은 이미지 데이터에 특화된 신경망 구조로, **합성곱 레이어**를 통해 핵심적인 특징을 추출한다. 커널(필터)은 모든 이미지에 동일하게 적용되며, 적은 파라미터로도 높은 성능을 낼 수 있다.

**예시**

```python
# CNN 합성곱 레이어 예시
import torch.nn as nn

cnn = nn.Sequential(
    nn.Conv2d(1, 8, kernel_size=3, padding=1),
    nn.ReLU(),
    nn.MaxPool2d(2)
)
```

**주의사항**  
- 합성곱 레이어를 반복적으로 쌓은 후, 평탄화(Flatten)하여 완전연결층에 연결한다.
- 입력 데이터의 크기와 커널 크기를 일치시켜야 한다.

---

## 트랜스포머(Transformer) 🧠

**설명**  
**트랜스포머(Transformer)** 는 자연어 처리에서 시작된 구조로, 최근에는 이미지, 동영상 등 다양한 분야에 적용되고 있다. **Self-Attention** 메커니즘을 통해 입력의 모든 요소 간 관계를 효율적으로 학습한다.

**예시**

```python
# 트랜스포머 인코더 예시 (PyTorch)
import torch.nn as nn

transformer_encoder = nn.TransformerEncoder(
    nn.TransformerEncoderLayer(d_model=32, nhead=4), num_layers=2
)
sample_input = torch.randn(10, 8, 32)  # (seq_len, batch, d_model)
output = transformer_encoder(sample_input)
```

**주의사항**  
- 트랜스포머는 대규모 데이터와 연산 자원이 필요하다.
- 최신 인공지능 서비스(예: ChatGPT, 이미지 생성 모델 등)에 널리 활용된다.