# 1. 피쳐 엔지니어링 기법 🧩

## 목차 📑

### 1. 데이터셋이 내포하기 쉬운 문제점들
- [1.1 데이터셋의 정의와 중요성](#데이터셋의-정의와-중요성-) 📚
- [1.2 불완전한 데이터셋](#불완전한-데이터셋-) 🚫
- [1.3 불균형한 데이터셋](#불균형한-데이터셋-) ⚖️
- [1.4 이상치 데이터](#이상치-데이터-) ❗

### 2. 정규화 및 표준화
- [2.1 정규화](#정규화-) 🔄
- [2.2 표준화](#표준화-) 📏

### 3. 상관관계 분석
- [3.1 상관관계의 개념](#상관관계의-개념-) 🔗
- [3.2 상관계수와 히트맵](#상관계수와-히트맵-) 🌡️

### 4. 불필요한 구성 요소 제거
- [4.1 과적합 문제](#과적합-문제-) 🛑
- [4.2 상관관계 기반 불필요 요소 식별](#상관관계-기반-불필요-요소-식별-) 🧹

### 5. 도메인 지식
- [5.1 도메인 지식의 정의와 역할](#도메인-지식의-정의와-역할-) 🧠
- [5.2 도메인 지식 활용 예시](#도메인-지식-활용-예시-) 💡

### 6. 피처 엔지니어링 기법
- [6.1 연속형 데이터 전처리](#연속형-데이터-전처리-) 📈
- [6.2 범주형 데이터 전처리](#범주형-데이터-전처리-) 🏷️
- [6.3 결측치 대체](#결측치-대체-) 🕳️
- [6.4 불균형 데이터 샘플링](#불균형-데이터-샘플링-) ⚖️

---

## 데이터셋의 정의와 중요성 📚

**설명**  
**데이터셋**은 인공지능 모델이 학습할 수 있도록 핵심 데이터를 모아놓은 집합이다. 컴퓨터가 이해할 수 있는 형태로 변환된 정보(숫자, 이미지, 텍스트, 음성 등)로 구성되며, 일반적으로 **정답 데이터(라벨)** 를 포함한다. 데이터셋의 **양과 질**은 모델의 성능에 직접적인 영향을 미친다.

**예시**

```python
# 예시: 간단한 텍스트 분류용 데이터셋 생성
dataset = [
    {"text": "오늘은 맑은 날씨입니다.", "label": "날씨"},
    {"text": "주식 시장이 상승세를 보입니다.", "label": "경제"},
    {"text": "축구 경기가 열렸습니다.", "label": "스포츠"}
]
```

**주의사항**  
데이터셋이 충분하지 않거나 품질이 낮으면, 인공지능 모델의 성능이 크게 저하될 수 있다.

---

## 불완전한 데이터셋 🚫

**설명**  
**불완전한 데이터셋**이란, 필요한 데이터 항목이 처음부터 누락되어 있는 경우를 의미한다. 이러한 데이터셋은 아무리 모델을 개선해도 성능 향상이 어렵고, 심한 경우 전체 데이터를 폐기하고 재수집해야 할 수도 있다. 따라서 문제 정의와 데이터 수집 계획을 명확히 수립해야 한다.

**예시**

```python
# 예시: 숙박 요금 예측에서 요일 정보가 누락된 데이터
hotel_data = [
    {"price": 120000, "holiday": True},  # 요일 정보 없음
    {"price": 95000, "holiday": False}
]
```

**주의사항**  
핵심 피처가 누락된 데이터는 분석 및 예측에 치명적인 영향을 미치므로, 데이터 수집 단계에서부터 필요한 항목을 빠짐없이 확보해야 한다.

---

## 불균형한 데이터셋 ⚖️

**설명**  
**불균형 데이터셋**은 각 라벨(클래스)별 데이터의 양이 현저하게 차이나는 경우를 말한다. 인공지능 모델은 데이터가 많은 클래스를 우선적으로 학습하는 경향이 있어, 소수 클래스의 예측 성능이 저하된다.

**예시**

```python
# 예시: 고양이와 강아지 이미지 분류에서 강아지 데이터가 압도적으로 많은 경우
labels = ["cat"] * 20 + ["dog"] * 200
```

**주의사항**  
데이터 수집 단계에서 클래스별로 균형을 맞추는 것이 가장 효과적이다. 불균형이 심할 경우, 샘플링 기법 등으로 보완해야 한다.

---

## 이상치 데이터 ❗

**설명**  
**이상치(Outlier)** 란, 데이터 분포에서 현저히 벗어난 값을 의미한다. 이상치는 센서 오류, 입력 실수, 자연적 예외 등 다양한 원인으로 발생한다. 적은 수의 이상치는 큰 영향을 미치지 않지만, 명확한 이상치는 제거하는 것이 바람직하다.

**예시**

```python
# 예시: 온도 센서 데이터에서 비정상적으로 높은 값이 포함된 경우
temperatures = [22, 23, 21, 22, 100, 23, 22]  # 100은 이상치
```

**주의사항**  
이상치 판단 기준은 데이터의 분포와 도메인 특성에 따라 달라질 수 있다. 대표적으로 **Z-Score**를 이용해 평균에서 3 표준편차 이상 벗어난 값을 이상치로 간주한다.

---

## 정규화 🔄

**설명**  
**정규화(Normalization)** 는 데이터의 값을 일정한 범위(주로 0~1)로 변환하는 과정이다. 이는 서로 다른 스케일의 피처를 동일한 기준으로 맞추어, 모델 학습의 효율을 높인다. 정규화는 이상치 제거 후, 최솟값과 최댓값을 이용해 수행한다.

**예시**

```python
# 예시: 0~1 정규화
import numpy as np

scores = np.array([50, 80, 90, 100])
min_val = scores.min()
max_val = scores.max()
normalized = (scores - min_val) / (max_val - min_val)
print(normalized)  # [0.   0.6  0.8  1.0]
```

**주의사항**  
정규화는 이상치가 존재할 경우 왜곡될 수 있으므로, 반드시 이상치 제거 후 적용해야 한다.

---

## 표준화 📏

**설명**  
**표준화(Standardization)** 는 데이터의 평균을 0, 표준편차를 1로 변환하는 과정이다. 데이터가 **정규분포**를 따를 때 특히 효과적이며, 많은 머신러닝 알고리즘이 입력 데이터가 정규분포임을 전제로 한다.

**예시**

```python
# 예시: 표준화
import numpy as np

values = np.array([10, 12, 14, 16, 18])
mean = values.mean()
std = values.std()
standardized = (values - mean) / std
print(standardized)
```

**주의사항**  
표준화는 데이터가 정규분포를 따르지 않을 경우 효과가 제한적일 수 있다. 데이터의 분포를 사전에 확인하는 것이 중요하다.

---

## 상관관계의 개념 🔗

**설명**  
**상관관계**는 두 변수 간의 선형적 관계의 정도를 나타낸다. 상관관계 분석은 피처 엔지니어링의 기초로, 변수들 사이의 연관성을 직관적으로 파악할 수 있다.

**예시**

```python
# 예시: 두 변수의 상관계수 계산
import numpy as np

x = np.array([1, 2, 3, 4, 5])
y = np.array([2, 4, 6, 8, 10])
correlation = np.corrcoef(x, y)[0, 1]
print(f"상관계수: {correlation}")  # 1.0
```

**주의사항**  
상관관계가 높다고 해서 반드시 인과관계가 존재하는 것은 아니다.

---

## 상관계수와 히트맵 🌡️

**설명**  
**상관계수(Pearson Correlation Coefficient)** 는 -1에서 1 사이의 값을 가지며, 1에 가까울수록 양의 상관관계, -1에 가까울수록 음의 상관관계를 의미한다. **히트맵(Heatmap)** 은 변수 간 상관관계를 시각적으로 표현하는 도구로, 상관계수가 클수록 진한 색으로 표시된다.

**예시**

```python
# 예시: DataFrame의 상관관계 히트맵 시각화
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

df = pd.DataFrame({
    "A": [1, 2, 3, 4],
    "B": [2, 4, 6, 8],
    "C": [5, 3, 2, 1]
})
corr = df.corr()
sns.heatmap(corr, annot=True, cmap="coolwarm")
plt.show()
```

**주의사항**  
자기 자신과의 상관계수는 항상 1이다. 히트맵을 통해 예측 변수와 상관관계가 높은 피처를 쉽게 확인할 수 있다.

---

## 과적합 문제 🛑

**설명**  
**과적합(Overfitting)** 은 모델이 학습 데이터의 불필요한 패턴이나 잡음을 과도하게 학습하여, 새로운 데이터에 대한 예측 성능이 저하되는 현상이다. 이는 불필요한 피처가 포함되어 있을 때 자주 발생한다.

**예시**

```python
# 예시: 불필요한 피처가 포함된 데이터
data = [
    {"feature1": 10, "feature2": 5, "irrelevant": 999, "label": 1},
    {"feature1": 12, "feature2": 7, "irrelevant": 888, "label": 0}
]
```

**주의사항**  
불필요한 피처는 모델의 복잡도를 높이고, 예측 성능을 저하시킬 수 있으므로, 반드시 제거해야 한다.

---

## 상관관계 기반 불필요 요소 식별 🧹

**설명**  
상관관계 분석을 통해 예측하고자 하는 변수와 강한 상관관계를 갖는 피처만을 남기고, 나머지는 불필요한 요소로 간주하여 제거할 수 있다. 반대로, 예측 변수와 상관관계가 약한 피처는 비선형적 관계를 가질 수 있으므로, 도메인 지식과 함께 신중히 판단해야 한다.

**예시**

```python
# 예시: 상관관계가 낮은 피처 제거
import pandas as pd

df = pd.DataFrame({
    "target": [1, 2, 3, 4],
    "related": [2, 4, 6, 8],
    "unrelated": [7, 7, 7, 7]
})
corr = df.corr()
# 'unrelated' 피처는 상관계수가 0에 가까우므로 제거 후보
```

**주의사항**  
상관관계만으로 피처를 제거하면, 비선형적 관계나 도메인 특성을 간과할 수 있으므로 주의해야 한다.

---

## 도메인 지식의 정의와 역할 🧠

**설명**  
**도메인 지식(Domain Knowledge)** 이란, 특정 분야에 대한 전문적 이해와 정보를 의미한다. 경험, 교육, 훈련 등을 통해 축적되며, 인공지능 모델 개발 시 전문가의 지식이 개입되는 경우가 많다. 때로는 도메인 지식이 모델 성능 향상의 핵심이 되기도 한다.

**예시**

```python
# 예시: 화학 데이터에서 원소 이름 대신 원소 번호 사용
data = [
    {"element_number": 8, "property": 3.5},  # 산소
    {"element_number": 11, "property": 2.1}  # 나트륨
]
```

**주의사항**  
도메인 지식 없이 상관관계만으로 피처를 선택하면, 인과관계를 잘못 해석할 위험이 있다.

---

## 도메인 지식 활용 예시 💡

**설명**  
도메인 지식은 데이터 전처리와 피처 선택 과정에서 중요한 역할을 한다. 예를 들어, 원소의 이름은 사람이 임의로 정한 것이므로, 원소의 특성을 예측할 때 이름 자체는 불필요하다. 또한, pH와 수소 이온 농도처럼 수학적으로 연관된 피처가 있을 경우, 중복 정보를 제거하는 것이 바람직하다.

**예시**

```python
# 예시: pH와 수소 이온 농도(log 관계) 중 하나만 사용
data = [
    {"ph": 7.0, "h_concentration": None},  # 둘 중 하나만 남김
    {"ph": 5.5, "h_concentration": None}
]
```

**주의사항**  
상관관계가 높다고 해서 인과관계가 있는 것은 아니므로, 도메인 전문가의 판단이 반드시 필요하다.

---

## 연속형 데이터 전처리 📈

**설명**  
**연속형 데이터**는 값의 범위가 넓고, 고유값이 많은 숫자형 데이터를 의미한다. 정확한 수치가 중요하지 않은 경우, 구간화(이산화)를 통해 복잡성을 줄일 수 있다. 구간 설정 시 도메인 지식을 활용하면 모델의 과적합을 방지할 수 있다.

**예시**

```python
# 예시: 나이 데이터를 연령대 구간으로 변환
import pandas as pd

df = pd.DataFrame({"age": [15, 22, 37, 45, 61]})
df["age_group"] = pd.cut(df["age"], bins=[0, 19, 29, 39, 49, 100], labels=["10대", "20대", "30대", "40대", "50대 이상"])
print(df)
```

**주의사항**  
구간화는 정보 손실을 유발할 수 있으므로, 실제 분석 목적에 맞게 신중히 적용해야 한다.

---

## 범주형 데이터 전처리 🏷️

**설명**  
**범주형 데이터**는 주로 문자열로 표현되며, 고유값의 개수가 적고 대부분 순서가 없다. 전처리 방법으로는 **원-핫 인코딩(One-Hot Encoding)** 과 **순서 인코딩**이 있다.

### 원-핫 인코딩

각 범주마다 새로운 피처를 생성하고, 해당 범주에 속하면 1, 아니면 0을 할당한다.

```python
# 예시: 원-핫 인코딩
import pandas as pd

df = pd.DataFrame({"city": ["서울", "부산", "서울", "대구"]})
df_encoded = pd.get_dummies(df, columns=["city"])
print(df_encoded)
```

### 순서 인코딩

범주형 데이터에 순서가 있을 때, 각 범주를 순서대로 숫자로 변환한다.

```python
# 예시: 순서 인코딩
import pandas as pd

df = pd.DataFrame({"grade": ["하", "중", "상", "중", "상"]})
grade_order = {"하": 1, "중": 2, "상": 3}
df["grade_encoded"] = df["grade"].map(grade_order)
print(df)
```

**주의사항**  
원-핫 인코딩은 범주 수가 많을 경우 메모리와 계산 효율이 저하될 수 있다. 순서 인코딩은 순서가 없는 데이터에 적용하면 오히려 왜곡을 초래할 수 있다.

---

## 결측치 대체 🕳️

**설명**  
**결측치(Missing Value)** 란, 데이터가 비어 있거나 측정에 실패한 경우를 의미한다. 결측치는 평균, 중앙값, 최빈값 등 대표값으로 대체하거나, 예측 모델 또는 다중 대체 기법을 사용할 수 있다.

**예시**

```python
# 예시: 평균값으로 결측치 대체
import pandas as pd
import numpy as np

df = pd.DataFrame({"score": [85, np.nan, 90, 88, np.nan]})
mean_score = df["score"].mean()
df["score_filled"] = df["score"].fillna(mean_score)
print(df)
```

**주의사항**  
결측치 처리 방법에 따라 분석 결과가 달라질 수 있으므로, 데이터의 특성과 목적에 맞게 신중히 선택해야 한다.

---

## 불균형 데이터 샘플링 ⚖️

**설명**  
**불균형 데이터 샘플링**은 범주형 데이터 예측 문제에서, 각 클래스의 데이터 수가 불균형할 때 샘플링을 통해 균형을 맞추는 기법이다. **오버샘플링**은 소수 클래스를 복제하여 데이터 수를 늘리고, **언더샘플링**은 다수 클래스를 줄여서 비율을 맞춘다.

**예시**

```python
# 예시: 오버샘플링 및 언더샘플링
from collections import Counter
import random

data = [("A", 1)] * 3 + [("B", 0)] * 10  # 클래스 A가 소수
# 오버샘플링: 클래스 A를 복제
oversampled = data + [("A", 1)] * 7
# 언더샘플링: 클래스 B를 일부만 사용
undersampled = [x for x in data if x[0] == "A"] + random.sample([x for x in data if x[0] == "B"], 3)
print(f"오버샘플링 후: {Counter([x[0] for x in oversampled])}")
print(f"언더샘플링 후: {Counter([x[0] for x in undersampled])}")
```

**주의사항**  
오버샘플링은 과적합을 유발할 수 있고, 언더샘플링은 정보 손실이 발생할 수 있으므로, 데이터 특성에 맞게 적절히 조합하여 사용해야 한다.
