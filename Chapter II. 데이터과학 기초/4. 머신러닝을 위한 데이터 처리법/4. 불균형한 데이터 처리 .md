# 4. 불균형 데이터 다루기: 소수의 목소리를 듣는 기술

## 목차
- [4. 불균형 데이터 다루기: 소수의 목소리를 듣는 기술](#4-불균형-데이터-다루기-소수의-목소리를-듣는-기술)
  - [목차](#목차)
  - [1. 데이터 불균형: 왜 심각한 문제인가?](#1-데이터-불균형-왜-심각한-문제인가)
    - [정확도(Accuracy)의 함정](#정확도accuracy의-함정)
  - [2. 올바르게 평가하기: 정밀도, 재현율, 그리고 F1-Score](#2-올바르게-평가하기-정밀도-재현율-그리고-f1-score)
    - [혼동 행렬 (Confusion Matrix)](#혼동-행렬-confusion-matrix)
  - [3. 불균형 데이터 처리 전략](#3-불균형-데이터-처리-전략)
    - [전략 1: 언더샘플링 (Undersampling)](#전략-1-언더샘플링-undersampling)
    - [전략 2: 오버샘플링 (Oversampling)](#전략-2-오버샘플링-oversampling)
    - [전략 3: 알고리즘 레벨에서 접근하기 (`class_weight`)](#전략-3-알고리즘-레벨에서-접근하기-class_weight)
  - [4. 어떤 전략을 언제 사용해야 하는가?](#4-어떤-전략을-언제-사용해야-하는가)

---

## 1. 데이터 불균형: 왜 심각한 문제인가?

**데이터 불균형(Imbalanced Data)**  은 분류 문제에서 각 클래스에 속한 데이터의 양이 현저하게 차이 나는 상황을 말합니다. (예: 정상 클래스 99%, 이상 클래스 1%)

이런 데이터로 모델을 학습시키면, 모델은 어려운 소수 클래스를 맞추기보다, 그냥 **모든 것을 다수 클래스로 예측하는 손쉬운 길**을 택하게 됩니다. 점수를 잘 받기 위해 어려운 문제는 포기하고 쉬운 문제만 푸는 것과 같습니다.

### 정확도(Accuracy)의 함정

- **문제 상황**: 1000개의 데이터 중 990개가 '정상', 10개가 '사기'인 데이터셋.
- **무능한 모델**: 모든 데이터를 '정상'으로만 예측.
- **모델의 정확도**: 990개를 맞췄으므로 99% !

이처럼 정확도는 불균형 데이터에서 모델의 성능을 심각하게 왜곡합니다. 우리는 '사기'라는 소수 클래스를 얼마나 잘 탐지하는지에 관심이 있는데도 말이죠.

## 2. 올바르게 평가하기: 정밀도, 재현율, 그리고 F1-Score

불균형 데이터를 평가하기 위해서는 정확도 대신 다음 지표들을 사용해야 합니다.

### 혼동 행렬 (Confusion Matrix)

| | 예측: Positive | 예측: Negative |
| :--- | :--- | :--- |
| **실제: Positive** | True Positive (TP) | False Negative (FN) |
| **실제: Negative** | False Positive (FP) | True Negative (TN) |

- **정밀도 (Precision)**  = `TP / (TP + FP)`
  - **"Positive라고 예측한 것들 중, 진짜 Positive는 얼마나 되는가?"** 
  - 스팸 메일 필터에서 중요: 정상 메일을 스팸으로 잘못 분류(FP)하면 안 되므로.
- **재현율 (Recall)**  = `TP / (TP + FN)`
  - **"실제 Positive인 것들 중, 모델이 얼마나 많이 Positive라고 맞췄는가?"** 
  - 암 진단 모델에서 중요: 실제 암 환자를 놓치면(FN) 안 되므로.
- **F1-Score** = `2 * (Precision * Recall) / (Precision + Recall)`
  - 정밀도와 재현율의 **조화 평균**. 두 지표가 모두 중요할 때 사용되는 균형 잡힌 지표입니다.

## 3. 불균형 데이터 처리 전략

### 전략 1: 언더샘플링 (Undersampling)

- **방법**: **다수 클래스**의 데이터 수를 줄여 소수 클래스의 수에 맞춥니다.
- **대표 기법**:
    - **RandomUnderSampler**: 다수 클래스에서 무작위로 데이터를 제거. 가장 간단하지만 정보 손실의 위험이 있습니다.
    - **Tomek Links**: 서로 다른 클래스이면서 가장 가까운 이웃인 데이터 쌍(Tomek Link)을 찾아서, 그 중 다수 클래스의 데이터를 제거합니다. 클래스 간의 경계를 명확하게 만드는 효과가 있습니다.
- **언제 사용하는가?**: 전체 데이터의 양이 **매우 클 때** 효과적입니다. 일부 데이터를 잃어도 학습에 큰 문제가 없을 때 사용합니다.

### 전략 2: 오버샘플링 (Oversampling)

- **방법**: **소수 클래스**의 데이터 수를 늘려 다수 클래스의 수에 맞춥니다.
- **대표 기법**:
    - **RandomOverSampler**: 소수 클래스의 데이터를 무작위로 복제. 과적합(Overfitting)의 위험이 있습니다.
    - **SMOTE (Synthetic Minority Over-sampling Technique)** : 소수 클래스 데이터와 그 이웃 데이터들 사이에 **새로운 가상의 데이터를 생성**합니다. 단순 복제보다 훨씬 정교하며, 과적합 위험을 줄여줍니다. 가장 널리 쓰이는 오버샘플링 기법입니다.
- **언제 사용하는가?**: 전체 데이터의 양이 **충분하지 않을 때** 주로 사용됩니다. 정보 손실을 피하고 싶을 때 좋은 선택입니다.

```python
from collections import Counter
from sklearn.datasets import make_classification
from imblearn.over_sampling import SMOTE

# 불균형 데이터 생성
X, y = make_classification(n_samples=1000, n_features=10, n_informative=5,
                           n_redundant=0, n_classes=2, n_clusters_per_class=1,
                           weights=[0.99, 0.01], random_state=42)

print(f"원본 데이터 클래스 분포: {Counter(y)}")

# SMOTE 적용
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X, y)

print(f"SMOTE 적용 후 클래스 분포: {Counter(y_resampled)}")
```

### 전략 3: 알고리즘 레벨에서 접근하기 (`class_weight`)

- **방법**: 샘플링으로 데이터 자체를 바꾸는 대신, 모델이 학습할 때 **소수 클래스의 데이터에 더 큰 가중치(중요도)** 를 부여합니다.
- **설명**: 모델이 소수 클래스 데이터를 틀렸을 때, 다수 클래스 데이터를 틀렸을 때보다 훨씬 더 큰 페널티(손실)를 받게 됩니다. 이로써 모델은 자연스럽게 소수 클래스를 맞추는 데 더 집중하게 됩니다.
- **언제 사용하는가?**: 대부분의 트리 기반 모델(Decision Tree, RandomForest, XGBoost 등)과 로지스틱 회귀, SVM 등에서 `class_weight='balanced'` 라는 간단한 파라미터 설정만으로 적용할 수 있어 매우 편리하고 효과적입니다.

```python
from sklearn.linear_model import LogisticRegression

# class_weight='balanced' 옵션으로 모델 생성
# 모델이 자동으로 클래스 빈도의 역수에 비례하는 가중치를 부여함
model = LogisticRegression(class_weight='balanced', random_state=42)
```

## 4. 어떤 전략을 언제 사용해야 하는가?

| 상황 | 추천 전략 | 이유 |
| :--- | :--- | :--- |
| **데이터가 매우 많을 때** | **언더샘플링** | 정보 손실의 영향이 적고, 학습 속도가 빨라짐 |
| **데이터가 적을 때** | **오버샘플링 (특히 SMOTE)**  | 정보 손실을 막고, 모델이 학습할 데이터를 늘려줌 |
| **간단하고 빠른 시도를 원할 때** | **`class_weight` 파라미터** | 데이터 변환 없이 모델 설정만으로 적용 가능 |
| **최상의 성능을 원할 때** | **오버샘플링 + 언더샘플링 조합** | (예: SMOTE + Tomek Links) |
