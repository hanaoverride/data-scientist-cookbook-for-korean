# 3. 실전 분류 모델링: 올바른 모델 선택과 성능 평가 전략

## 목차
- [3. 실전 분류 모델링: 올바른 모델 선택과 성능 평가 전략](#3-실전-분류-모델링-올바른-모델-선택과-성능-평가-전략)
  - [](#역할-persona)
  - [목차](#목차)
  - [1. 분류 모델 선택을 위한 핵심 고려사항](#1-분류-모델-선택을-위한-핵심-고려사항)
  - [2. 모델 비교 분석: 언제 무엇을 쓸 것인가?](#2-모델-비교-분석-언제-무엇을-쓸-것인가)
    - [빠르고 해석 가능한 모델이 필요할 때](#빠르고-해석-가능한-모델이-필요할-때)
    - [높은 예측 성능이 최우선일 때](#높은-예측-성능이-최우선일-때)
    - [데이터가 매우 크거나, 학습 속도가 중요할 때](#데이터가-매우-크거나-학습-속도가-중요할-때)
  - [3. 성능 평가: 무엇을 기준으로 모델을 평가할 것인가?](#3-성능-평가-무엇을-기준으로-모델을-평가할-것인가)
    - [상황 1: 스팸 메일 필터링 (정밀도가 중요)](#상황-1-스팸-메일-필터링-정밀도가-중요)
    - [상황 2: 암 진단 (재현율이 중요)](#상황-2-암-진단-재현율이-중요)
    - [상황 3: 균형 잡힌 성능 평가 (F1-Score, AUC)](#상황-3-균형-잡힌-성능-평가-f1-score-auc)
  - [4. 실전 예제: 유방암 데이터 분류 및 평가](#4-실전-예제-유방암-데이터-분류-및-평가)

---

## 1. 분류 모델 선택을 위한 핵심 고려사항

최적의 모델을 선택하기 위해 다음 4가지 요소를 종합적으로 고려해야 합니다.

1.  **데이터의 크기와 차원**: 데이터가 수백만 건 이상인가? 특성의 개수가 매우 많은가?
2.  **성능 (예측 정확도)** : 모델의 예측이 얼마나 정확해야 하는가?
3.  **속도 (학습 및 예측)** : 모델을 얼마나 빨리 학습시키고, 예측 결과를 얼마나 빨리 받아야 하는가?
4.  **해석 가능성 (Interpretability)** : "모델이 왜 그렇게 예측했는지"를 설명해야 하는가?

## 2. 모델 비교 분석: 언제 무엇을 쓸 것인가?

### 빠르고 해석 가능한 모델이 필요할 때

- **추천 모델**: **로지스틱 회귀(Logistic Regression), 의사결정나무(Decision Tree)** 
- **이유**:
    - **로지스틱 회귀**: 학습 속도가 매우 빠르고, 각 특성의 계수(coefficient)를 통해 어떤 특성이 예측에 긍정적/부정적 영향을 미치는지 명확하게 해석할 수 있습니다. 훌륭한 **베이스라인 모델**입니다.
    - **의사결정나무**: 'If-Then' 규칙의 조합으로 이루어져 있어, 모델의 의사결정 과정을 사람이 직관적으로 이해하기 쉽습니다.

### 높은 예측 성능이 최우선일 때

- **추천 모델**: **랜덤 포레스트(Random Forest), 그래디언트 부스팅 계열(XGBoost, LightGBM)** 
- **이유**:
    - **랜덤 포레스트**: 여러 개의 트리를 사용하는 앙상블 효과 덕분에 단일 결정 트리보다 훨씬 안정적이고 정확합니다. 과적합에 강하고, 비교적 튜닝이 쉽습니다.
    - **그래디언트 부스팅**: 이전 모델의 실수를 계속 보완해나가는 방식으로 학습하여, 현존하는 분류 모델 중 가장 높은 수준의 예측 정확도를 보여주는 경우가 많습니다. 데이터 분석 대회(Kaggle 등)의 우승 모델은 대부분 이 계열입니다.

### 데이터가 매우 크거나, 학습 속도가 중요할 때

- **추천 모델**: **나이브 베이즈(Naive Bayes), LightGBM**
- **이유**:
    - **나이브 베이즈**: 확률 계산 기반으로 매우 빠르게 학습할 수 있으며, 대용량 텍스트 데이터 분류 등에서 효과적입니다.
    - **LightGBM**: XGBoost보다 더 빠른 학습 속도와 적은 메모리 사용량을 목표로 개발되었습니다. 수백만 건 이상의 대용량 데이터를 다룰 때 최고의 선택지 중 하나입니다.

## 3. 성능 평가: 무엇을 기준으로 모델을 평가할 것인가?

모델의 성능을 평가할 때는 비즈니스 목적에 맞는 올바른 지표를 선택하는 것이 매우 중요합니다.

### 상황 1: 스팸 메일 필터링 (정밀도가 중요)

- **문제**: 정상 메일(Negative)을 스팸(Positive)으로 잘못 예측하면(FP), 사용자가 중요한 메일을 놓치게 되어 큰 문제가 됩니다.
- **핵심 지표**: **정밀도(Precision)**  = `TP / (TP + FP)`
- **목표**: FP를 최소화하여, 모델이 '스팸'이라고 예측한 결과의 신뢰도를 높이는 것이 중요합니다.

### 상황 2: 암 진단 (재현율이 중요)

- **문제**: 실제 암 환자(Positive)를 정상(Negative)으로 잘못 예측하면(FN), 환자의 생명이 위험해질 수 있습니다.
- **핵심 지표**: **재현율(Recall)**  = `TP / (TP + FN)`
- **목표**: FN을 최소화하여, 실제 환자를 한 명이라도 놓치지 않고 모두 찾아내는 것이 중요합니다.

### 상황 3: 균형 잡힌 성능 평가 (F1-Score, AUC)

- **문제**: 정밀도와 재현율 모두 중요한 경우, 또는 어떤 것을 더 우선해야 할지 모호한 경우.
- **핵심 지표**:
    - **F1-Score**: 정밀도와 재현율의 조화 평균. 두 지표가 한쪽에 치우치지 않고 모두 좋을 때 높은 점수를 받습니다.
    - **AUC (Area Under ROC Curve)** : 모델이 양성 클래스와 음성 클래스를 얼마나 잘 구별하는지를 나타내는 종합적인 성능 지표. 1에 가까울수록 좋습니다. 클래스 분포가 불균형할 때도 안정적인 평가가 가능합니다.

## 4. 실전 예제: 유방암 데이터 분류 및 평가

Scikit-learn의 유방암 진단 데이터셋을 사용하여, 여러 분류 모델의 성능을 AUC 점수로 비교해봅시다.

```python
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
import xgboost as xgb
from sklearn.metrics import roc_auc_score

# 1. 데이터 준비 및 전처리
cancer = load_breast_cancer()
X, y = cancer.data, cancer.target

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 2. 모델 학습 및 평가
models = {
    "Logistic Regression": LogisticRegression(random_state=42, max_iter=10000),
    "Random Forest": RandomForestClassifier(random_state=42),
    "XGBoost": xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')
}

for name, model in models.items():
    # 학습
    model.fit(X_train_scaled, y_train)
    # 예측 확률 계산
    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]
    # AUC 점수 계산
    auc = roc_auc_score(y_test, y_pred_proba)
    print(f"[{name}] - Test AUC: {auc:.4f}")
```
