# 4. 실전 프로젝트: 타이타닉 생존자 예측 모델 만들기 (End-to-End)

## 목차
- [1. 1단계: 문제 정의 및 데이터 로드](#1-1단계-문제-정의-및-데이터-로드)
- [2. 2단계: 탐색적 데이터 분석 (EDA)](#2-2단계-탐색적-데이터-분석-eda)
- [3. 3단계: 데이터 전처리 및 특성 공학](#3-3단계-데이터-전처리-및-특성-공학)
- [4. 4단계: 모델링 및 학습](#4-4단계-모델링-및-학습)
- [5. 5단계: 모델 평가](#5-5단계-모델-평가)

---

## 1. 1단계: 문제 정의 및 데이터 로드

- **문제**: 타이타닉호 승객 데이터를 바탕으로, 특정 승객의 **생존 여부를 예측**하는 이진 분류 문제입니다.
- **데이터**: `seaborn` 라이브러리에 내장된 'titanic' 데이터셋을 사용합니다.

```python
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# 데이터 로드
df = sns.load_dataset('titanic')

# 데이터의 첫인상 확인
print("--- 데이터 정보 ---")
df.info()
print("\n--- 데이터 샘플 ---")
print(df.head())
```

## 2. 2단계: 탐색적 데이터 분석 (EDA)

데이터에 숨겨진 패턴과 인사이트를 발견합니다.

- **질문 1**: "성별에 따라 생존율에 차이가 있는가?"
- **질문 2**: "좌석 등급(pclass)에 따라 생존율에 차이가 있는가?"

```python
plt.figure(figsize=(12, 5))

# 성별에 따른 생존율
plt.subplot(1, 2, 1)
sns.barplot(x='sex', y='survived', data=df)
plt.title('성별에 따른 생존율')

# 좌석 등급에 따른 생존율
plt.subplot(1, 2, 2)
sns.barplot(x='pclass', y='survived', data=df)
plt.title('좌석 등급에 따른 생존율')

plt.show()
```
> **탐색 결과**: 여성이 남성보다, 그리고 높은 등급의 좌석일수록 생존율이 훨씬 높다는 강력한 패턴을 발견했습니다. 이 두 특성은 매우 중요해 보입니다.

## 3. 3단계: 데이터 전처리 및 특성 공학

모델이 학습할 수 있도록 데이터를 깨끗하게 만들고, 새로운 특성을 생성합니다.

```python
# --- 불필요한 컬럼 제거 ---
# embark_town은 embarked와 중복, who/adult_male은 sex/age로 유추 가능
df.drop(['embark_town', 'who', 'adult_male'], axis=1, inplace=True)

# --- 결측치 처리 ---
# age: 중앙값으로 대체
df['age'].fillna(df['age'].median(), inplace=True)
# embarked, deck: 최빈값으로 대체 (deck은 너무 많지만 예제 단순화를 위해)
df['embarked'].fillna(df['embarked'].mode()[0], inplace=True);
df['deck'].fillna(df['deck'].mode()[0], inplace=True)

# --- 특성 공학 ---
# 1. 범주형 데이터 인코딩 (One-Hot Encoding)
df = pd.get_dummies(df, columns=['sex', 'embarked', 'class', 'deck'], drop_first=True)

# 2. 새로운 특성 생성
df['family_size'] = df['sibsp'] + df['parch']
df['is_alone'] = (df['family_size'] == 0).astype(int)

# 3. 최종 특성 선택
df.drop(['alive', 'sibsp', 'parch', 'pclass'], axis=1, inplace=True) # 중복되거나 불필요한 원본 컬럼 제거

print("\n--- 전처리 및 특성 공학 후 데이터 샘플 ---")
print(df.head())
```

## 4. 4단계: 모델링 및 학습

이제 준비된 데이터로 모델을 학습시킵니다.

```python
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier

# 1. 문제(X)와 정답(y) 분리
X = df.drop('survived', axis=1)
y = df['survived']

# 2. 훈련/테스트 데이터 분할
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 3. 데이터 스케일링
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 4. 모델 선택 및 학습
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train_scaled, y_train)

print("\n모델 학습 완료!")
```

## 5. 5단계: 모델 평가

학습된 모델이 새로운 데이터에 대해 얼마나 좋은 성능을 보이는지 평가합니다.

```python
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# 예측 수행
y_pred = model.predict(X_test_scaled)

# 성능 평가
accuracy = accuracy_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)
class_report = classification_report(y_test, y_pred)

print(f"\n--- 모델 평가 결과 ---")
print(f"정확도 (Accuracy): {accuracy:.4f}")
print("\n혼동 행렬 (Confusion Matrix):\n", conf_matrix)
print("\n분류 리포트 (Classification Report):\n", class_report)
```

> **결과 해석**: 약 81.5%의 정확도를 보이며, 생존(1)과 사망(0) 클래스에 대한 정밀도와 재현율을 확인할 수 있습니다. 이 결과를 바탕으로 모델을 더 튜닝하거나, 다른 모델과 비교하여 최종 모델을 선택할 수 있습니다.
