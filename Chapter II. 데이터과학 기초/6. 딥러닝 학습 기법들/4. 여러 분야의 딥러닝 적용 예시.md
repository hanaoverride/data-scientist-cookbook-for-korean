# 4. 여러 분야의 딥러닝 적용 예시 🧠

## 목차 📑

### 1. 딥러닝 개요 및 적용 분야
- [1.1 딥러닝 발전사](#딥러닝-발전사-) ⏳
- [1.2 딥러닝의 주요 적용 분야](#딥러닝의-주요-적용-분야-) 🌐

### 2. 이미지 처리와 딥러닝
- [2.1 이미지 처리 기술](#이미지-처리-기술-) 📷
- [2.2 컴퓨터의 이미지 인식 원리](#컴퓨터의-이미지-인식-원리-) 🖼️
- [2.3 합성곱 신경망(CNN) 개요](#합성곱-신경망cnn-개요-) 🧩
  - [CNN 구조](#cnn-구조)
  - [Convolution Layer](#convolution-layer)
  - [Padding과 Striding](#padding과-striding)
  - [Pooling Layer](#pooling-layer)
  - [Fully Connected Layer와 Softmax](#fully-connected-layer와-softmax)
  - [CNN의 응용](#cnn의-응용)

### 3. 자연어 처리와 딥러닝
- [3.1 자연어 처리 개요](#자연어-처리-개요-) 💬
- [3.2 자연어 처리 과정](#자연어-처리-과정-) 🛠️
  - [전처리: Noise Canceling, Tokenizing, StopWord 제거](#전처리-noise-canceling-tokenizing-stopword-제거)
- [3.3 워드 임베딩(Word Embedding)](#워드-임베딩word-embedding-) 🧱
  - [Bag of Words, One-hot, DTM, Word2vec](#bag-of-words-one-hot-dtm-word2vec)

### 4. 순환 신경망(RNN)과 자연어 처리
- [4.1 RNN 개요 및 구조](#rnn-개요-및-구조-) 🔄
- [4.2 RNN의 자연어 처리 응용](#rnn의-자연어-처리-응용-) 🤖

---

## 딥러닝 발전사 ⏳

**딥러닝**은 인공신경망을 기반으로 한 기계학습의 한 분야로, 1958년 **퍼셉트론**의 등장 이후 여러 차례의 발전과 침체기를 거쳐 2010년대에 본격적으로 각광받기 시작했다. 1986년에는 역전파 알고리즘이 제안되었으나, 연산 자원과 데이터 부족으로 한동안 정체기를 겪었다. 2012년 **ImageNet** 대회에서 딥러닝 기반 모델이 기존 방법을 압도적으로 능가하면서, 딥러닝은 다양한 분야에서 혁신을 이끌게 되었다.

> **주요 연혁**
> - 1958년: 퍼셉트론(Perceptron) 발표
> - 1969년/1990년: AI 겨울(First/Second AI Winter)
> - 1986년: 역전파(Backpropagation) 알고리즘
> - 2012년: 딥러닝 혁명(ImageNet 대회, AlexNet)
> - 2020년: 다양한 실전 적용 및 고도화

---

## 딥러닝의 주요 적용 분야 🌐

**딥러닝**은 특히 **비정형 데이터**(이미지, 텍스트 등)에 강점을 보이며, 다음과 같은 분야에 널리 활용된다.

- **이미지 처리**: 얼굴 인식, 화질 개선, 이미지 자동 태깅 등
- **자연어 처리**: 기계 번역, 음성 인식, 챗봇 등
- **기타**: 자율주행, 의료 영상 분석, 추천 시스템 등

> **주의사항**: 딥러닝은 대용량 데이터와 높은 연산 자원이 필요하며, 데이터 품질에 따라 성능이 크게 달라질 수 있다.

---

## 이미지 처리 기술 📷

**이미지 처리** 분야에서 딥러닝은 다음과 같은 기술로 활용된다.

- **얼굴 인식 카메라**: 실시간으로 사람의 얼굴을 인식하여 인증이나 보안에 사용
- **화질 개선(Super Resolution)**: 저해상도 이미지를 고해상도로 변환
- **이미지 자동 태깅**: 이미지 내 객체나 장면을 자동으로 분류 및 태깅

```python
# 이미지 자동 태깅 예시 (새로운 예시)
from PIL import Image
import numpy as np

# 가상의 이미지 데이터 (3x3 픽셀, 흑백)
img_array = np.array([[120, 130, 125],
                      [128, 140, 135],
                      [122, 138, 132]])

# 임계값을 기준으로 '밝음' 또는 '어두움' 태그 부여
tag = '밝음' if img_array.mean() > 130 else '어두움'
print(f"이미지 태그: {tag}")
```

> **주의사항**: 실제 이미지 분류는 훨씬 복잡한 모델과 대규모 데이터셋이 필요하다.

---

## 컴퓨터의 이미지 인식 원리 🖼️

컴퓨터는 이미지를 **픽셀 값의 배열**로 인식한다. 각 픽셀은 밝기나 색상 정보를 숫자로 표현하며, 이 숫자 배열이 신경망의 입력이 된다.

```python
# 2x2 흑백 이미지 예시
image = np.array([[200, 50],
                  [80,  255]])
print("이미지 배열:\n", image)
```

> **주의**: 컬러 이미지는 각 픽셀마다 RGB 3채널 값을 가진다.

---

## 합성곱 신경망(CNN) 개요 🧩

### CNN 구조

**합성곱 신경망(CNN)** 은 이미지의 **특징 추출**과 **분류**를 위해 다음과 같은 계층 구조를 가진다.

- **Convolution Layer**: 이미지에서 특징을 추출
- **Pooling Layer**: 특징 맵의 크기를 줄여 연산량 감소 및 노이즈 완화
- **Fully Connected Layer**: 추출된 특징을 바탕으로 최종 분류 수행

---

### Convolution Layer

**Convolution Layer**는 작은 **필터(커널)** 를 이미지 전체에 이동시키며, 각 위치에서의 특징을 추출하여 **특징 맵(feature map)** 을 생성한다.

```python
# 3x3 필터를 5x5 이미지에 적용하는 예시
image = np.array([[1, 2, 3, 0, 1],
                  [0, 1, 2, 3, 1],
                  [1, 0, 1, 2, 2],
                  [2, 1, 0, 1, 3],
                  [0, 2, 1, 0, 1]])
kernel = np.array([[0, 1, 0],
                   [1, -4, 1],
                   [0, 1, 0]])

# 단순 컨볼루션 연산 (중앙 위치만 계산)
feature = np.sum(image[1:4, 1:4] * kernel)
print("특징 값:", feature)
```

> **주의사항**: 실제 CNN에서는 모든 위치에 필터를 적용하며, 여러 개의 필터를 사용해 다양한 특징을 추출한다.

---

### Padding과 Striding

- **Padding**: 입력 이미지의 가장자리에 0 등으로 값을 추가하여 출력 크기를 조절
- **Striding**: 필터를 이동시키는 간격을 조절하여 출력 크기와 연산량을 조절

```python
# Padding 예시
padded_img = np.pad(image, pad_width=1, mode='constant', constant_values=0)
print("패딩 적용 이미지:\n", padded_img)

# Stride 적용 예시 (stride=2)
stride = 2
output = []
for i in range(0, image.shape[0] - 2, stride):
    for j in range(0, image.shape[1] - 2, stride):
        region = image[i:i+3, j:j+3]
        output.append(np.sum(region * kernel))
print("Stride=2 적용 결과:", output)
```

> **주의**: Padding과 Stride 설정에 따라 출력 크기와 정보 손실 정도가 달라진다.

---

### Pooling Layer

**Pooling Layer**는 특징 맵의 크기를 줄이고, 이미지의 왜곡이나 노이즈에 대한 민감도를 낮춘다. 대표적으로 **최대 풀링(Max Pooling)**과 **평균 풀링(Average Pooling)**이 있다.

```python
# 2x2 Max Pooling 예시
feature_map = np.array([[3, 1, 2, 4],
                        [5, 6, 1, 2],
                        [8, 7, 4, 3],
                        [2, 1, 5, 9]])
pooled = np.max(feature_map[:2, :2])
print("Max Pooling 결과:", pooled)
```

> **주의**: 풀링 크기와 방식에 따라 정보 손실이 발생할 수 있으므로, 적절한 설정이 필요하다.

---

### Fully Connected Layer와 Softmax

**Fully Connected Layer**는 앞서 추출된 특징을 바탕으로 최종 분류를 수행한다. 마지막 단계에서는 **Softmax** 활성화 함수를 사용하여 각 클래스에 대한 확률을 산출한다.

```python
# Softmax 예시
import numpy as np
scores = np.array([2.0, 1.0, 0.1])
exp_scores = np.exp(scores)
probs = exp_scores / np.sum(exp_scores)
print("Softmax 확률:", probs)
```

> **주의**: Softmax 출력은 항상 0~1 사이의 값이며, 전체 합이 1이 되도록 정규화된다.

---

### CNN의 응용

**CNN**은 이미지 분류 외에도 **객체 탐지(Object Detection)**, **이미지 분할(Segmentation)**, **초해상도(Super Resolution)** 등 다양한 이미지 처리 기술에 활용된다.

---

## 자연어 처리 개요 💬

**자연어 처리(Natural Language Processing, NLP)** 는 인간의 언어를 컴퓨터가 이해하고 처리할 수 있도록 변환하는 기술이다. 대표적인 응용 분야로는 **기계 번역**, **음성 인식**, **챗봇** 등이 있다.

---

## 자연어 처리 과정 🛠️

자연어 처리는 일반적으로 다음과 같은 단계로 이루어진다.

1. **자연어 전처리(Preprocessing)**: 원문에서 불필요한 요소를 제거하고, 분석에 적합한 형태로 변환
2. **단어 표현(Word Embedding)**: 단어를 수치 벡터로 변환
3. **모델 적용(Modeling)**: 신경망 등 기계학습 모델에 입력

### 전처리: Noise Canceling, Tokenizing, StopWord 제거

- **Noise Canceling**: 오타, 띄어쓰기 등 문장 내 오류를 교정
- **Tokenizing**: 문장을 의미 단위(단어, 형태소 등)로 분할
- **StopWord 제거**: 분석에 불필요한 단어(예: "그리고", "하지만" 등)를 삭제

```python
# 전처리 예시
import re

sentence = "딥러닝을  공부하고있습니다!"
# Noise Canceling: 공백 및 특수문자 정리
cleaned = re.sub(r'[^가-힣\s]', '', sentence)
# Tokenizing: 공백 기준 분할
tokens = cleaned.split()
# StopWord 제거 예시
stopwords = ['을', '하고']
filtered = [word for word in tokens if word not in stopwords]
print("전처리 결과:", filtered)
```

> **주의**: 언어별, 목적별로 전처리 방법이 달라질 수 있다.

---

## 워드 임베딩(Word Embedding) 🧱

**워드 임베딩**은 자연어의 각 단어를 **수치 벡터**로 변환하여 컴퓨터가 처리할 수 있도록 하는 기법이다. 주요 방식은 다음과 같다.

### Bag of Words, One-hot, DTM, Word2vec

- **Bag of Words**: 문서 내 단어의 출현 여부만을 고려하여 벡터화
- **One-hot Encoding**: 전체 단어 집합 크기만큼의 벡터에서 해당 단어 위치만 1, 나머지는 0
- **Document Term Matrix(DTM)**: 각 문서별로 단어의 등장 빈도를 행렬로 표현
- **Word2vec**: 의미적으로 유사한 단어가 가까운 벡터 공간에 위치하도록 학습

```python
# One-hot Encoding 예시
vocab = ['고양이', '강아지', '토끼', '말']
sentence = ['고양이', '토끼']
one_hot = [1 if word in sentence else 0 for word in vocab]
print("One-hot 벡터:", one_hot)

# Word2vec 유사 예시 (임의의 벡터 할당)
word_vectors = {
    '고양이': [0.2, 0.8],
    '강아지': [0.1, 0.9],
    '토끼': [0.3, 0.7],
    '말': [0.9, 0.1]
}
print("고양이 벡터:", word_vectors['고양이'])
```

> **주의**: One-hot 방식은 차원이 매우 커질 수 있으며, Word2vec 등 분산 표현은 의미적 유사성을 반영할 수 있다.

---

## RNN 개요 및 구조 🔄

**순환 신경망(RNN, Recurrent Neural Network)** 은 시퀀스 데이터(문장, 음성 등)에서 **이전 정보의 맥락**을 반영할 수 있도록 설계된 신경망 구조이다. 입력이 순차적으로 처리되며, 각 시점의 출력이 다음 시점의 입력에 영향을 준다.

- **입력 노드**: 한 번에 하나의 벡터(주로 원-핫 벡터)를 입력
- **은닉 상태**: 이전 시점의 정보를 기억하여 다음 연산에 활용
- **출력 노드**: 각 시점마다 결과를 출력

```python
# RNN 구조 예시 (단순 구현)
import numpy as np

def simple_rnn_step(x_t, h_prev, Wxh, Whh, Why):
    h_t = np.tanh(np.dot(Wxh, x_t) + np.dot(Whh, h_prev))
    y_t = np.dot(Why, h_t)
    return h_t, y_t

# 임의의 입력, 가중치, 초기 은닉 상태
x_t = np.array([1, 0, 0])
h_prev = np.zeros(2)
Wxh = np.random.randn(2, 3)
Whh = np.random.randn(2, 2)
Why = np.random.randn(1, 2)
h_t, y_t = simple_rnn_step(x_t, h_prev, Wxh, Whh, Why)
print("은닉 상태:", h_t)
print("출력:", y_t)
```

> **주의**: RNN은 긴 시퀀스에서 **기울기 소실/폭주** 문제가 발생할 수 있으며, 이를 개선한 LSTM, GRU 등이 존재한다.

---

## RNN의 자연어 처리 응용 🤖

**RNN**은 자연어 분류, 감정 분석, 기계 번역, 이미지 캡셔닝 등 다양한 시퀀스 데이터 처리에 활용된다.

- **자연어 분류**: 문장이나 문서의 감정(긍정/부정 등) 분류
- **이미지 캡셔닝**: 이미지 내용을 설명하는 문장 생성
- **챗봇**: 대화형 응답 생성

```python
# 감정 분류 예시 (가상의 입력)
sentences = ["오늘 날씨가 좋아서 기분이 좋아요", "숙제가 많아서 힘들다"]
labels = [1, 0]  # 1: 긍정, 0: 부정

# 임의의 벡터 변환 및 RNN 입력 (실제 모델 학습 과정은 생략)
for sent, label in zip(sentences, labels):
    print(f"문장: {sent} -> 레이블: {label}")
```

> **주의**: 실제 RNN 기반 자연어 처리 모델은 대량의 데이터와 복잡한 전처리, 임베딩, 하이퍼파라미터 튜닝이 필요하다.