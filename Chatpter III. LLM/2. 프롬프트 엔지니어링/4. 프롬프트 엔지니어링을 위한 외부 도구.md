# 4. LLM의 한계 극복하기: LangChain으로 외부 세계와 연결

## 목차
- [1. LLM의 근본적인 한계](#1-llm의-근본적인-한계)
- [2. 한계 극복의 열쇠: LangChain 프레임워크](#2-한계-극복의-열쇠-langchain-프레임워크)
  - [LangChain의 핵심 철학: LLM을 부품처럼 조립하기](#langchain의-핵심-철학-llm을-부품처럼-조립하기)
- [3. 실전 1: LLM에게 최신 정보 알려주기 (검색 에이전트)](#3-실전-1-llm에게-최신-정보-알려주기-검색-에이전트)
- [4. 실전 2: LLM에게 파일 읽고 요약시키기 (문서 분석)](#4-실전-2-llm에게-파일-읽고-요약시키기-문서-분석)
- [5. 실전 3: LLM에게 계산 능력 부여하기 (계산기 에이전트)](#5-실전-3-llm에게-계산-능력-부여하기-계산기-에이전트)

---

## 1. LLM의 근본적인 한계

LLM은 그 자체로 매우 강력하지만, 다음과 같은 명백한 한계를 가집니다.
- **최신성 부족**: 특정 시점까지의 데이터로만 학습되어, 최신 정보를 알지 못합니다.
- **사실 왜곡 (할루시네이션)** : 학습 데이터에 기반하여 그럴듯한 거짓말을 만들어낼 수 있습니다.
- **외부 세계와의 단절**: 웹 검색, 데이터베이스 조회, 다른 프로그램 실행 등 외부 세계와 상호작용할 수 없습니다.
- **긴 맥락 처리의 어려움**: 한 번에 처리할 수 있는 입력 토큰의 양에 제한이 있어, 매우 긴 문서를 한 번에 이해하기 어렵습니다.

## 2. 한계 극복의 열쇠: LangChain 프레임워크

**LangChain**은 이러한 LLM의 한계를 극복하기 위해, LLM을 **외부 데이터 소스 및 다른 프로그램(도구)**  과 쉽게 연결하고 조합할 수 있도록 도와주는 오픈소스 프레임워크입니다.

### LangChain의 핵심 철학: LLM을 부품처럼 조립하기

LangChain은 LLM을 단독으로 사용하는 것이 아니라, 다양한 기능(검색, 계산, DB 조회 등)을 가진 '부품'들과 **'체인(Chain)'** 또는 **'에이전트(Agent)'** 라는 형태로 조립하여 더 복잡하고 강력한 애플리케이션을 만들 수 있게 합니다.

- **체인 (Chain)** : LLM과 다른 구성 요소를 순차적으로 연결하여 특정 작업을 수행합니다. (예: 문서 로드 -> 텍스트 분할 -> 요약 -> 출력)
- **에이전트 (Agent)** : LLM이 스스로 **[생각 -> 행동 -> 관찰]** 사이클을 돌며, 어떤 도구를 사용해야 할지 직접 결정하고 작업을 수행합니다. (ReAct 프레임워크 기반)

## 3. 실전 1: LLM에게 최신 정보 알려주기 (검색 에이전트)

LLM에게 웹 검색 능력을 부여하여, 최신 정보에 기반한 답변을 생성하게 만들어 봅시다.

```python
# !pip install langchain langchain-openai google-search-results
import os
from langchain_openai import OpenAI
from langchain.agents import load_tools, initialize_agent, AgentType

# API 키 설정 (실제 키를 입력해야 합니다)
# os.environ["OPENAI_API_KEY"] = "YOUR_OPENAI_API_KEY"
# os.environ["SERPAPI_API_KEY"] = "YOUR_SERPAPI_API_KEY"

# LLM과 도구 로드
llm = OpenAI(temperature=0)
tools = load_tools(["serpapi"], llm=llm)

# 에이전트 초기화
agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)

# 에이전트 실행
question = "2024년 UEFA 챔피언스리그 우승팀은 어디야?"
agent.run(question)
```
> **작동 원리**: 에이전트는 질문을 받고, `serpapi`(구글 검색 도구)를 사용해야겠다고 '생각'합니다. 검색 결과를 '관찰'한 뒤, 그 정보를 바탕으로 최종 답변을 생성합니다.

## 4. 실전 2: LLM에게 파일 읽고 요약시키기 (문서 분석)

LLM의 토큰 제한을 극복하고 긴 문서를 요약하기 위해, LangChain의 **요약 체인(Summarization Chain)**  을 사용합니다.

```python
# !pip install pypdf
from langchain_openai import OpenAI
from langchain.chains.summarize import load_summarize_chain
from langchain.document_loaders import PyPDFLoader

# PDF 파일 로드 및 분할
loader = PyPDFLoader("example.pdf") # 요약할 PDF 파일
docs = loader.load_and_split()

# LLM 및 요약 체인 초기화
llm = OpenAI(temperature=0)
# map_reduce: 문서를 여러 청크로 나누어 각각 요약한 뒤, 그 요약본들을 다시 합쳐 최종 요약
chain = load_summarize_chain(llm, chain_type="map_reduce")

# 요약 실행
summary = chain.run(docs)
print(summary)
```

## 5. 실전 3: LLM에게 계산 능력 부여하기 (계산기 에이전트)

LLM은 복잡한 수학 계산에 약합니다. 검색 능력과 함께 계산기 도구를 부여하여, 사실 확인과 계산을 모두 수행하는 에이전트를 만들어 봅시다.

```python
# LLM, 검색 도구, 계산기 도구 로드
llm = OpenAI(temperature=0)
tools = load_tools(["serpapi", "llm-math"], llm=llm)

# 에이전트 초기화
agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)

# 에이전트 실행
question = "테슬라의 현재 주가를 52주 최고가로 나눈 값은 얼마야?"
agent.run(question)
```
> **작동 원리**: 에이전트는 먼저 `serpapi`로 '테슬라 현재 주가'와 '52주 최고가'를 검색합니다. 검색된 두 숫자를 '관찰'한 뒤, 이 두 숫자를 나누기 위해 `llm-math`(계산기) 도구를 사용해야겠다고 '생각'하고, 최종 계산 결과를 답변으로 내놓습니다.
