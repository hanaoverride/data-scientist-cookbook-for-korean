# 5. 프롬프트 비식별화 개념과 기법 🛡️

## 목차 📑

### 1. 프롬프트 보안의 필요성
- [1.1 민감정보 유출 사례](#민감정보-유출-사례-) 🔓
- [1.2 비식별화의 개념](#비식별화의-개념-) 🕵️

### 2. 식별자 마스킹
- [2.1 개체명 인식(NER) 활용](#개체명-인식ner-활용-) 🏷️
- [2.2 마스킹 및 원상복구](#마스킹-및-원상복구-) 🔄

### 3. 가짜 식별자 생성
- [3.1 Faker 라이브러리 활용](#faker-라이브러리-활용-) 🧪
- [3.2 가짜 식별자 적용 및 번역](#가짜-식별자-적용-및-번역-) 🌐

---

## 민감정보 유출 사례 🔓

### 설명

**프롬프트 엔지니어링** 과정에서 외부 AI 서비스(예: ChatGPT)에 민감한 정보를 입력하는 사례가 빈번하게 발생하고 있다. 실제로 기업 직원의 약 4.7%가 회사의 내부 정보, 소스코드, 고객 데이터, 개인정보, 건강정보 등 **민감정보**를 AI 서비스에 입력한 경험이 있으며, 전체 입력 데이터의 11%가 민감정보로 확인된다. 이러한 데이터는 AI 서비스의 지식베이스에 저장되어 외부로 유출될 위험이 있다. 실제로 대기업에서 소스코드와 내부 회의록이 AI 서비스로 유출된 사례가 보고되었으며, AI 서비스의 버그로 인해 결제 정보 등 추가적인 개인정보가 노출된 사례도 있다.

### 예시

```python
# 잘못된 프롬프트 입력 예시 (가상의 데이터)
prompt = """
고객 이름: 박민수
주민등록번호: 900101-1234567
계좌번호: 123-9876-543210
문의 내용: 지난달 거래 내역을 알려주세요.
"""
# 이와 같은 프롬프트는 외부 서비스에 입력 시 보안 위험이 있다.
```

### 주의사항

- **외부 AI 서비스에 민감정보를 입력하는 것은 정보 유출로 이어질 수 있으므로 반드시 사전에 비식별화 처리가 필요하다.**
- **AI 서비스의 버그나 정책 변경으로 인해 입력된 데이터가 외부에 노출될 수 있음을 항상 염두에 두어야 한다.**

---

## 비식별화의 개념 🕵️

### 설명

**비식별화**란 데이터에서 개인을 식별할 수 있는 정보를 제거하거나 변형하여, 해당 데이터만으로는 특정 개인을 알아볼 수 없도록 만드는 과정이다. **식별자**는 이름, 주민등록번호, 이메일, 계좌번호, 의료 영상 등과 같이 1:1로 개인을 특정할 수 있는 정보를 의미한다. **준식별자**는 단독으로는 식별이 어렵지만, 다른 데이터와 결합할 경우 개인을 추론할 수 있는 정보(예: 거주 도시, 체중, 혈액형 등)이다.

### 예시

```python
# 식별자와 준식별자 예시
record = {
    "이름": "김하늘",           # 식별자
    "이메일": "skyblue@abc.com", # 식별자
    "거주지": "부산광역시",      # 준식별자
    "혈액형": "A",              # 준식별자
    "진료기록": "MRI_20230401.dcm" # 식별자
}
```

### 주의사항

- **식별자뿐만 아니라 준식별자도 결합 시 개인 식별이 가능하므로, 비식별화 시 모두 고려해야 한다.**
- **비식별화가 불완전할 경우, 데이터 재식별 위험이 존재한다.**

---

## 개체명 인식(NER) 활용 🏷️

### 설명

**식별자 마스킹**은 입력 프롬프트에서 식별자를 자동으로 탐지하고, 이를 의미 없는 토큰으로 대체하는 과정이다. 이를 위해 **개체명 인식(Named Entity Recognition, NER)** 기술이 활용된다. NER은 텍스트에서 사람 이름, 기관명, 날짜, 주소, 계좌번호 등 다양한 엔터티를 자동으로 식별한다. 파이썬에서는 `transformers` 라이브러리와 사전학습된 한국어 NER 모델(예: KoELECTRA 등)을 활용할 수 있다.

### 예시

```python
from transformers import AutoTokenizer, AutoModelForTokenClassification
import torch

# 사전학습된 NER 모델과 토크나이저 불러오기 (가상의 모델명 사용)
tokenizer = AutoTokenizer.from_pretrained("sample-ner-model")
model = AutoModelForTokenClassification.from_pretrained("sample-ner-model")

# 예시 문장
sentence = "고객 박하늘의 계좌 987-6543-210123로 5월 20일 오후 2시에 송금해주세요. 문의는 blue@sample.com으로 부탁드립니다."

# 토큰화 및 모델 예측
inputs = tokenizer(sentence, return_tensors="pt")
outputs = model(**inputs)
predictions = torch.argmax(outputs.logits, dim=-1)

# 토큰별 엔터티 태그 추출(가상의 로직)
tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])
entity_tags = [model.config.id2label[idx] for idx in predictions[0].tolist()]

# 토큰과 엔터티 태그 매핑 결과 출력
for token, tag in zip(tokens, entity_tags):
    print(f"{token}: {tag}")
```

**출력 예시**:
```
고객: O
박하늘: PERSON
의: O
계좌: O
987-6543-210123: ACCOUNT
로: O
5월: DATE
20일: DATE
오후: TIME
2시: TIME
에: O
송금: O
해주세요: O
.: O
문의: O
는: O
blue@sample.com: EMAIL
으로: O
부탁: O
드립니다: O
.: O
```

### 주의사항

- **NER 모델의 성능에 따라 일부 식별자가 누락될 수 있으므로, 추가적인 규칙 기반 탐지와 병행하는 것이 바람직하다.**
- **모델에 따라 엔터티 태그명이 다를 수 있으니, 사용 전 태그 체계를 반드시 확인해야 한다.**

---

## 마스킹 및 원상복구 🔄

### 설명

식별자 마스킹은 NER 결과를 바탕으로, 식별자에 해당하는 단어를 의미 없는 토큰(예: `###PERSON1###`, `###DATE2###` 등)으로 치환하는 과정이다. 마스킹된 프롬프트는 외부 AI 서비스에 안전하게 전달할 수 있다. 이후, AI의 응답 결과에서 마스킹 토큰을 원래 식별자로 복원하는 **원상복구** 과정을 거친다.

### 예시

```python
# 마스킹 예시
sentence = "고객 박하늘의 계좌 987-6543-210123로 5월 20일 오후 2시에 송금해주세요."
entity_map = {
    "박하늘": "###PERSON1###",
    "987-6543-210123": "###ACCOUNT2###",
    "5월 20일": "###DATE3###",
    "오후 2시": "###TIME4###"
}

# 마스킹 처리
masked_sentence = sentence
for original, mask in entity_map.items():
    masked_sentence = masked_sentence.replace(original, mask)

print(masked_sentence)
# 출력: 고객 ###PERSON1###의 계좌 ###ACCOUNT2###로 ###DATE3### ###TIME4###에 송금해주세요.

# 원상복구 예시 (AI 응답 결과에서)
ai_response = "Please transfer the amount to ###ACCOUNT2### for ###PERSON1### by ###DATE3### at ###TIME4###."
for mask, original in {v: k for k, v in entity_map.items()}.items():
    ai_response = ai_response.replace(mask, original)

print(ai_response)
# 출력: Please transfer the amount to 987-6543-210123 for 박하늘 by 5월 20일 at 오후 2시.
```

### 주의사항

- **마스킹 토큰은 중복되지 않도록 고유하게 생성해야 하며, 원상복구를 위해 매핑 정보를 안전하게 관리해야 한다.**
- **AI 응답에서 마스킹 토큰이 변형되거나 누락될 경우, 원상복구가 어려울 수 있으므로 주의가 필요하다.**

---

## Faker 라이브러리 활용 🧪

### 설명

**가짜 식별자 생성**은 실제 식별자를 무작위로 생성된 가짜 데이터로 대체하는 방법이다. 이를 통해 실제 정보 노출 없이 AI 서비스의 기능을 테스트하거나, 데이터 유출 위험을 최소화할 수 있다. 파이썬의 **Faker** 라이브러리는 이름, 주소, 이메일, 날짜, 계좌번호 등 다양한 가짜 데이터를 손쉽게 생성할 수 있다.

### 예시

```python
from faker import Faker

fake = Faker('ko_KR')

# 가짜 식별자 생성 예시
print(fake.name())         # 예: 이지훈
print(fake.address())      # 예: 경기도 수원시 팔달구 장안로 123
print(fake.email())        # 예: minjae.kim@example.com
print(fake.date())         # 예: 1992-11-23
print(fake.company())      # 예: 미래정보기술(주)
print(fake.phone_number()) # 예: 010-1234-5678
```

### 주의사항

- **Faker로 생성된 데이터는 실제 존재하지 않는 정보이므로, 테스트 및 비식별화 목적 외에는 사용하지 않아야 한다.**
- **가짜 식별자 사용 시, 원래 데이터와 형식이 유사하도록 생성해야 AI 서비스의 처리 결과가 자연스럽게 유지된다.**

---

## 가짜 식별자 적용 및 번역 🌐

### 설명

가짜 식별자 생성은 마스킹과 유사하게, NER로 탐지된 식별자 위치에 Faker로 생성한 임의의 값을 삽입하는 방식으로 진행된다. 이렇게 생성된 프롬프트는 실제 정보 노출 없이 외부 AI 서비스에 전달할 수 있다. 번역, 요약 등 다양한 AI 작업 후에도 가짜 식별자는 그대로 유지되거나, 필요에 따라 원상복구가 가능하다.

### 예시

```python
from faker import Faker

fake = Faker('ko_KR')

# 원본 문장과 엔터티 태그 예시
sentence = "고객 박하늘의 계좌 987-6543-210123로 5월 20일 오후 2시에 송금해주세요."
entity_tags = {
    "박하늘": "PERSON",
    "987-6543-210123": "ACCOUNT",
    "5월 20일": "DATE",
    "오후 2시": "TIME"
}

# 가짜 식별자 생성 및 치환
fake_entities = {
    "PERSON": fake.name(),
    "ACCOUNT": fake.bban(),
    "DATE": fake.date(),
    "TIME": fake.time()
}

masked_sentence = sentence
for original, tag in entity_tags.items():
    masked_sentence = masked_sentence.replace(original, fake_entities[tag])

print(masked_sentence)
# 예시 출력: 고객 김민재의 계좌 12345678901234로 2001-07-15 14:23:45에 송금해주세요.
```

### 주의사항

- **가짜 식별자 사용 시, 번역 등 AI 작업 결과에서 원상복구가 불가능할 수 있으므로, 실제 정보가 필요한 경우에는 마스킹 방식과 병행하는 것이 좋다.**
- **가짜 식별자와 실제 데이터가 혼동되지 않도록, 테스트 환경과 실제 운영 환경을 명확히 구분해야 한다.**