# 5. 안전한 프롬프트를 위한 데이터 비식별화 기술

## 목차
- [1. 왜 비식별화가 필수적인가?: LLM과 정보 유출 리스크](#1-왜-비식별화가-필수적인가-llm과-정보-유출-리스크)
- [2. 비식별화의 첫걸음: 민감정보 탐지하기 (NER)](#2-비식별화의-첫걸음-민감정보-탐지하기-ner)
  - [개체명 인식 (NER) 이란?](#개체명-인식-ner-이란)
- [3. 비식별화 처리 기법](#3-비식별화-처리-기법)
  - [기법 1: 마스킹 (Masking)](#기법-1-마스킹-masking)
  - [기법 2: 가명 처리 (Pseudonymization) with Faker](#기법-2-가명-처리-pseudonymization-with-faker)
- [4. 비식별화 기술의 한계와 주의사항](#4-비식별화-기술의-한계와-주의사항)

---

## 1. 왜 비식별화가 필수적인가?: LLM과 정보 유출 리스크

외부 LLM 서비스(ChatGPT, Claude 등)에 프롬프트를 입력하면, 그 데이터는 서비스 제공자의 서버로 전송되며 모델의 추가 학습에 사용될 수 있습니다. 이는 다음과 같은 심각한 리스크를 야기합니다.

- **개인정보 유출**: 고객의 이름, 연락처, 주소, 주민등록번호 등
- **기업 기밀 유출**: 미공개 소스 코드, 내부 회의록, 재무 데이터 등

실제로 다수의 기업에서 민감정보가 LLM 서비스를 통해 유출된 사례가 보고되었습니다. 따라서, 외부 LLM에 데이터를 보내기 전에는 반드시 **비식별화(De-identification)**  과정을 거쳐야 합니다.

## 2. 비식별화의 첫걸음: 민감정보 탐지하기 (NER)

비식별화를 하려면, 먼저 텍스트 내에서 어떤 부분이 민감정보인지 알아내야 합니다. 이 역할을 하는 기술이 바로 **개체명 인식(NER, Named Entity Recognition)**  입니다.

### 개체명 인식 (NER) 이란?

NER은 텍스트에서 '사람(PER)', '기관(ORG)', '장소(LOC)', '날짜(DATE)' 등 고유한 의미를 갖는 개체명을 자동으로 식별하고 태깅하는 자연어 처리 기술입니다. 우리는 이 기술을 활용하여 프롬프트에 포함된 이름, 주민등록번호, 이메일, 주소 등의 민감정보를 탐지할 수 있습니다.

```python
# NER 모델을 사용한 민감정보 탐지 예시 (개념 코드)
# 실제로는 사전 학습된 NER 모델을 사용해야 합니다.

def detect_entities(text):
    # 이 함수는 실제 NER 모델의 동작을 흉내 냅니다.
    entities = []
    if "김민준" in text:
        entities.append(("김민준", "PERSON"))
    if "service@example.com" in text:
        entities.append(("service@example.com", "EMAIL"))
    return entities

prompt = "고객 김민준님의 문의 메일은 service@example.com 입니다."
detected = detect_entities(prompt)
print(f"탐지된 개체: {detected}")
```

## 3. 비식별화 처리 기법

NER을 통해 민감정보를 탐지했다면, 이를 안전한 형태로 바꿔주어야 합니다.

### 기법 1: 마스킹 (Masking)

- **방법**: 탐지된 민감정보를 `[PERSON_1]`, `[EMAIL_1]` 과 같이 의미 없는 고유한 태그로 완전히 대체합니다.
- **장점**: 원본 정보가 완전히 제거되어 보안성이 매우 높습니다.
- **단점**: LLM이 문맥을 이해하는 데 필요한 정보까지 제거하여, 답변의 품질이 저하될 수 있습니다.
- **원상복구**: LLM의 답변을 받은 후, 이 태그들을 원래의 정보로 다시 치환하는 '원상복구' 과정이 필요합니다.

```python
# 마스킹 및 원상복구 예시
original_text = "담당자 김민준(010-1234-5678)에게 연락하세요."
mapping = {
    "김민준": "[PERSON_1]",
    "010-1234-5678": "[PHONE_1]"
}
reverse_mapping = {v: k for k, v in mapping.items()}

# 마스킹
masked_text = original_text.replace("김민준", mapping["김민준"]).replace("010-1234-5678", mapping["010-1234-5678"])
print(f"마스킹된 텍스트: {masked_text}")

# LLM의 가상 답변
llm_response = "연락처 [PHONE_1]로 [PERSON_1]님께 연락했습니다."

# 원상복구
unmasked_response = llm_response.replace(reverse_mapping["[PERSON_1]"], "김민준").replace(reverse_mapping["[PHONE_1]"], "010-1234-5678")
print(f"원상복구된 답변: {unmasked_response}")
```

### 기법 2: 가명 처리 (Pseudonymization) with Faker

- **방법**: 탐지된 민감정보를, 실제 데이터는 아니지만 형식은 동일한 **가짜 데이터**로 대체합니다. (예: '김민준' -> '이서연', '010-1234-5678' -> '010-9876-5432')
- **장점**: 데이터의 원래 형식을 유지하므로, 마스킹보다 LLM이 문맥을 더 잘 이해하여 답변의 품질 저하가 적습니다.
- **단점**: 원상복구가 불가능하므로, LLM의 답변에 원본 정보가 포함될 필요가 없는 경우에 사용합니다.
- **도구**: 파이썬의 `Faker` 라이브러리를 사용하면 고품질의 가짜 데이터를 쉽게 생성할 수 있습니다.

```python
# !pip install Faker
from faker import Faker

fake = Faker('ko_KR')

# 가짜 데이터 생성
fake_name = fake.name()
fake_phone = fake.phone_number()

print(f"생성된 가짜 이름: {fake_name}")
print(f"생성된 가짜 전화번호: {fake_phone}")

# 원본 텍스트에 적용
original_text = "담당자 김민준(010-1234-5678)에게 연락하세요."
anonymized_text = original_text.replace("김민준", fake_name).replace("010-1234-5678", fake_phone)
print(f"가명 처리된 텍스트: {anonymized_text}")
```

## 4. 비식별화 기술의 한계와 주의사항

- **NER 모델의 불완전성**: NER 모델은 100% 완벽하지 않습니다. 신조어, 오타, 비정형적인 형태의 민감정보는 탐지하지 못할 수 있습니다. 따라서 정규표현식(Regex) 기반의 규칙 탐지를 병행하는 것이 안전합니다.
- **답변 품질 저하**: 마스킹이나 가명 처리는 LLM이 문맥을 이해하는 데 방해가 될 수 있습니다. 이로 인해 답변의 논리나 자연스러움이 떨어질 수 있습니다.
- **재식별 위험**: 준식별자(나이, 도시, 성별 등)들이 여러 개 결합되면 개인을 특정할 수 있는 재식별 위험이 여전히 존재합니다.