# 3. 고급 프롬프트 엔지니어링: AI를 똑똑하게 만드는 생각의 사슬

## 목차
- [1. AI는 왜 복잡한 추론에 실패하는가?](#1-ai는-왜-복잡한-추론에-실패하는가)
- [2. 기술 1: 생각의 사슬 (Chain-of-Thought, CoT) 프롬프팅](#2-기술-1-생각의-사슬-chain-of-thought-cot-프롬프팅)
  - [CoT의 원리: 생각할 시간을 주어라](#cot의-원리-생각할-시간을-주어라)
  - [CoT 프롬프트 작성법](#cot-프롬프트-작성법)
- [3. 기술 2: ReAct 프롬프팅 (Reason + Act)](#3-기술-2-react-프롬프팅-reason--act)
  - [ReAct의 원리: 생각하고, 행동하고, 관찰하라](#react의-원리-생각하고-행동하고-관찰하라)
  - [ReAct 프롬프트의 구조](#react-프롬프트의-구조)
- [4. 자율 에이전트(Autonomous Agent)로의 확장](#4-자율-에이전트autonomous-agent로의-확장)

---

## 1. AI는 왜 복잡한 추론에 실패하는가?

LLM은 다음에 올 단어를 확률적으로 예측하는 방식으로 작동합니다. 이 방식은 간단한 질문에는 효과적이지만, 여러 단계의 논리적 추론이 필요한 수학 문제나 계획 수립 문제에서는 성급하게 잘못된 결론으로 건너뛰는 경향이 있습니다. 중간 과정을 생략하고 답만 빨리 내놓으려다 실수를 하는 것입니다.

## 2. 기술 1: 생각의 사슬 (Chain-of-Thought, CoT) 프롬프팅

**CoT**는 LLM이 정답을 바로 내놓게 하는 대신, **정답에 도달하기까지의 중간 추론 과정을 단계별로 생각하고 작성하도록 유도**하는 프롬프팅 기법입니다.

### CoT의 원리: 생각할 시간을 주어라

복잡한 문제를 작은 단계들로 나누어 순서대로 풀게 하면, 각 단계는 이전 단계의 결과를 입력으로 받는 더 간단한 문제가 됩니다. 이는 LLM의 연산 부담을 줄여주고, 각 단계에서 실수가 발생할 확률을 낮추어 최종적인 정답의 정확도를 크게 향상시킵니다.

### CoT 프롬프트 작성법

#### 방법 1: Few-shot CoT
프롬프트에 단계별 풀이 과정이 포함된 몇 개의 예시를 제공합니다.

> **[프롬프트 예시]**
> Q: Roger는 테니스 공 5개를 가지고 시작했습니다. 그는 2통의 테니스 공을 더 샀습니다. 각 통에는 3개의 테니스 공이 들어있습니다. 그는 지금 몇 개의 테니스 공을 가지고 있습니까?
> A: Roger는 5개의 공으로 시작했습니다. 2통의 테니스 공은 각각 3개의 공을 가지고 있으므로 2 * 3 = 6개의 공입니다. 5 + 6 = 11. 정답은 11입니다.
>
> Q: 한 카페에 5개의 사과가 있었습니다. 그들은 2개의 사과를 더 사고, 사과 3개로 파이를 만들었습니다. 남은 사과는 몇 개입니까?
> A:

#### 방법 2: Zero-shot CoT
예시 없이, 프롬프트 끝에 간단한 마법의 문장을 추가합니다.

> **[프롬프트 예시]**
> Q: 한 카페에 5개의 사과가 있었습니다. 그들은 2개의 사과를 더 사고, 사과 3개로 파이를 만들었습니다. 남은 사과는 몇 개입니까?
> A: **Let's think step by step.** (자, 이제 단계별로 생각해 보자.)

이 한 문장만으로도 LLM은 스스로 추론 과정을 먼저 생성한 뒤 답을 내놓는 방식으로 작동하여, 정답률이 크게 향상됩니다.

## 3. 기술 2: ReAct 프롬프팅 (Reason + Act)

LLM은 최신 정보나 구체적인 사실을 모르고, 복잡한 계산을 못한다는 한계가 있습니다. **ReAct**는 이러한 LLM의 한계를 **외부 도구(Tool)**  와의 연동을 통해 극복하는 프레임워크입니다.

### ReAct의 원리: 생각하고, 행동하고, 관찰하라

ReAct는 LLM이 **[생각 -> 행동 -> 관찰]** 사이클을 반복하도록 설계합니다.
1.  **생각 (Thought)** : 현재 문제 상황을 분석하고, 다음 목표를 달성하기 위한 계획을 세웁니다.
2.  **행동 (Action)** : 계획을 수행하기 위해 필요한 **외부 도구**를 사용합니다. (예: `Search[검색어]`, `Calculator[계산식]`)
3.  **관찰 (Observation)** : 도구 사용의 결과를 확인하고, 이 새로운 정보를 바탕으로 다음 '생각'을 이어갑니다.

이 사이클을 반복하며, 최종 정답에 도달할 때까지 정보를 수집하고 추론을 발전시킵니다.

### ReAct 프롬프트의 구조

> **[프롬프트 예시]**
> 질문: Apple Inc.의 창립자와 현재 CEO는 각각 누구인가요?
>
> **생각 1**: 먼저 Apple Inc.의 창립자를 찾아야겠다.
> **행동 1**: `Search["Apple Inc. founders"]`
> **관찰 1**: 검색 결과에 따르면, Apple Inc.는 스티브 잡스, 스티브 워즈니악, 로널드 웨인에 의해 창립되었다.
>
> **생각 2**: 이제 현재 CEO를 찾아야겠다.
> **행동 2**: `Search["current CEO of Apple Inc."]`
> **관찰 2**: 검색 결과에 따르면, Apple Inc.의 현재 CEO는 팀 쿡이다.
>
> **생각 3**: 창립자와 현재 CEO 정보를 모두 찾았다. 이제 종합하여 최종 답변을 할 수 있다.
> **최종 답변**: Apple Inc.의 창립자는 스티브 잡스, 스티브 워즈니악, 로널드 웨인이며, 현재 CEO는 팀 쿡입니다.

## 4. 자율 에이전트(Autonomous Agent)로의 확장

ReAct 프레임워크를 기반으로, 사용자가 최종 목표만 제시하면 LLM이 스스로 **[생각 -> 행동 -> 관찰]** 사이클을 반복하며 작업을 완료하는 **자율 에이전트**를 만들 수 있습니다. Auto-GPT, AgentGPT 등이 대표적인 예시이며, 이는 LLM을 단순한 질의응답 시스템을 넘어, 복잡한 작업을 자율적으로 수행하는 '지능형 행위자'로 만드는 핵심 기술입니다.
