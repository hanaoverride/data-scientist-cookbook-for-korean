# 4. LLM과 이미지 생성 AI 👟🤖

## 목차 📑

### 1. 컴퓨터 비전과 이미지 생성
- [1.1 컴퓨터 비전과 이미지 생성](#컴퓨터-비전과-이미지-생성-)
- [1.2 이미지 생성 모델의 발전](#이미지-생성-모델의-발전-)
- [1.3 Diffusion 모델의 원리](#diffusion-모델의-원리-)
- [1.4 Text-to-Image 구조](#text-to-image-구조-)

### 2. Diffusion 기반 서비스와 비교
- [2.1 대표 서비스 소개](#대표-서비스-소개-)
- [2.2 서비스별 특징](#서비스별-특징-)
- [2.3 비교 요약](#비교-요약-)

### 3. 구현 및 활용
- [3.1 코드 구조 및 UI 개선](#코드-구조-및-ui-개선-)
- [3.2 예시 및 동작 흐름](#예시-및-동작-흐름-)
- [3.3 주의사항](#주의사항-)

---


## 컴퓨터 비전과 이미지 생성 🖼️

**컴퓨터 비전**은 컴퓨터가 디지털 이미지를 분석하고 이해하여 인간의 시각적 인지 능력을 모방하는 기술이다. 컴퓨터 비전의 주요 목적은 판별(분류, 객체 탐지, 이미지 분할)과 생성(새로운 이미지 생성)으로 나뉜다.

- **판별 모델(Discriminative Models)**: 입력 이미지를 분류하거나, 객체를 탐지, 이미지 내 영역을 분할하는 데 사용된다.
- **생성 모델(Generative Models)**: 입력 데이터의 패턴을 학습하여 새로운 이미지를 생성한다. 예로 스타일 전이, 이미지 복원, 텍스트-비디오 변환, 2D-3D 변환 등이 있다.

---

## 이미지 생성 모델의 발전 📈

이미지 생성 분야에서는 다음과 같은 주요 모델이 발전해왔다.

- **VAE(Variational Auto Encoder)**: 학습이 안정적이고 노이즈에 강하나, 생성 이미지의 품질이 낮은 편이다.
- **GAN(Generative Adversarial Network)**: 매우 정교한 이미지를 생성할 수 있으나, 학습이 불안정하고 다양한 이미지를 생성하는 데 한계가 있다.
- **Diffusion 모델**: VAE와 GAN의 장점을 결합하여, 우수한 이미지 품질과 다양한 표현, 안정적인 학습을 동시에 달성한다. 최근에는 상업적 이미지 생성, 이미지 복원, 결함 검출 등 다양한 분야에 활용되고 있다.

---

## Diffusion 모델의 원리 🔬

**Diffusion 모델**은 확산의 원리를 기반으로 한다. 이 모델은 다음과 같은 두 단계로 동작한다.

1. **Forward Process**: 여러 단계에 걸쳐 원본 이미지에 점진적으로 노이즈를 추가하여, 최종적으로는 완전히 무작위화된 이미지를 만든다.
2. **Reverse Process**: 신경망을 이용해 노이즈가 추가된 이미지를 점진적으로 복원하여, 원본 이미지와 유사한 새로운 이미지를 생성한다.

이 과정은 이미지 생성의 품질과 다양성을 동시에 확보할 수 있도록 설계되어 있다.

---

## Text-to-Image 구조 📝→🖼️

현대의 Diffusion 기반 이미지 생성 애플리케이션은 **Text-to-Image** 구조를 따른다. 사용자가 입력한 프롬프트(텍스트)는 **CLIP(Contrastive Language-Image Pretraining)** 과 같은 모델을 통해 텍스트 임베딩으로 변환된다. 이 임베딩을 조건으로 하여, Diffusion 모델이 해당 프롬프트에 맞는 이미지를 생성한다.

```python
# 예시: 텍스트 프롬프트를 이미지 생성에 활용하는 의사코드
user_prompt = "노란색 우산을 쓴 소년이 비오는 거리에서 걷는 모습"
text_embedding = clip_model.encode_text(user_prompt)
generated_image = diffusion_model.generate(text_embedding)
```

> **주의사항**: 프롬프트의 구체성과 명확성이 이미지 생성 결과에 큰 영향을 미친다.

---

## 대표 서비스 소개 🏆

Diffusion 기반 이미지 생성 서비스는 다양하게 존재하며, 대표적으로 다음과 같은 서비스가 있다.

- **DALL-E**: OpenAI에서 제공하는 이미지 생성 서비스로, 내부 구조는 비공개이며 API 또는 ChatGPT+ 구독을 통해 사용 가능하다. 다국어 프롬프트 이해 능력이 뛰어나며, 이미지 편집 기능(Inpainting/Outpainting)도 지원한다.
- **Midjourney**: Discord 채널에서 동작하는 Text-to-Image 생성 프로그램이다. 명령어 또는 일반 텍스트 프롬프트를 통해 이미지를 생성하며, 구독 플랜에 따라 사용량이 결정된다.
- **Stable Diffusion**: Stability AI에서 공개한 오픈소스 모델로, 학습된 가중치와 모델이 공개되어 다양한 오픈소스 프레임워크(WebUI, ComfyUI 등) 및 라이브러리(Hugging Face Diffusers)에서 활용 가능하다. 개인 디바이스에서 커스터마이징 및 추가 학습이 가능하다.

---

## 서비스별 특징 🔍

| 서비스명           | 특징                                                         |
|--------------------|-------------------------------------------------------------|
| **DALL-E**         | 방대한 이미지 데이터로 학습, GPT와 연동성 높음, 규제 강함, ChatGPT+ 구독 시 추가 요금 없이 사용 가능, 이미지 편집 지원 |
| **Midjourney**     | Discord 기반 커뮤니티 활성, 명령어 및 텍스트 프롬프트 지원, 구독 플랜에 따라 무제한 생성 가능, 커뮤니티 공유 활발 |
| **Stable Diffusion** | 오픈소스, 다양한 하드웨어에서 사용 가능, 모델 커스터마이징 용이, 작업물 공유 및 커뮤니티 활성, 하드웨어 요구 사항 존재 |

---

## 비교 요약 📝

- **DALL-E**는 API 및 ChatGPT+와의 연동성이 높고, 프롬프트 해석력이 우수하다. 다만, 이미지 생성에 대한 규제가 엄격하다.
- **Midjourney**는 커뮤니티 중심의 서비스로, 다양한 스타일의 이미지를 쉽고 빠르게 생성할 수 있다.
- **Stable Diffusion**은 오픈소스 기반으로, 사용자가 직접 모델을 커스터마이즈하거나 로컬에서 실행할 수 있다는 점이 강점이다.

---

## 코드 구조 및 UI 개선 🖥️

- **GPT**가 세 가지 서로 다른 여행 스타일과 각 여행별 추천 색상(RGB)을 반환한다.
- 각 여행은 UI에서 버튼으로 표시되며, 버튼 아래에는 추천 색상 팔레트가 시각적으로 나타난다.
- 사용자가 버튼을 클릭하면, 해당 여행과 색상 정보가 프롬프트로 변환되어 **DALL-E**에 전달된다.
- 프롬프트에는 사용자의 요청, GPT의 추천 목록, 그리고 사용자의 선택이 모두 포함된다.

```python
# 예시: 여행 추천 UI 및 이미지 생성 연동
import streamlit as st

# 가상의 여행 추천 결과
trips = [
    {"style": "도시 탐방", "colors": [[220, 20, 60], [245, 245, 220], [0, 0, 0]]},
    {"style": "자연 휴양", "colors": [[30, 144, 255], [255, 255, 255], [255, 215, 0]]},
    {"style": "역사 문화", "colors": [[128, 0, 128], [210, 180, 140], [255, 250, 205]]}
]

# UI 표시
for idx, trip in enumerate(trips):
    if st.button(f"{trip['style']} 선택"):
        selected = trip
        st.write(f"선택한 여행 스타일: {selected['style']}")
        st.write(f"추천 색상: {selected['colors']}")
        # DALL-E 프롬프트 생성 및 API 호출 (생략)
```

---

## 예시 및 동작 흐름 🧑‍💻

1. **사용자 입력**:  
   "친구와 봄 소풍을 갈 만한 여행지를 추천해줘."
2. **GPT 출력**:  
   - 여행 1: 벚꽃이 흐드러진 공원(연분홍 [255,182,193]), 강변 산책로(청색 [70,130,180]), 피크닉 존(흰색 [255,255,255])
   - 여행 2, 3: (생략)
3. **UI**:  
   - 각 여행별 버튼 및 색상 팔레트 표시
4. **사용자 선택**:  
   - 여행 1 선택
5. **DALL-E 프롬프트 생성**:  
   - "연분홍 벚꽃 공원, 청색 강변 산책로, 흰색 피크닉 존이 어우러진 봄 소풍 여행지"
6. **이미지 생성 및 표시**

---

## 주의사항 ⚠️

- **프롬프트의 구체성**이 이미지 생성 품질에 직접적인 영향을 미치므로, 가능한 한 명확하고 상세하게 작성해야 한다.
- **DALL-E**와 같은 사유화 모델은 내부 구조에 접근할 수 없으며, API 사용 시 요금 정책 및 사용 제한을 반드시 확인해야 한다.
- **Stable Diffusion** 등 오픈소스 모델은 하드웨어 요구 사항이 있으므로, 로컬 실행 시 시스템 사양을 고려해야 한다.
- 추천 색상(RGB) 정보는 실제 의상 색상과 다를 수 있으므로, 참고용으로 활용해야 한다.