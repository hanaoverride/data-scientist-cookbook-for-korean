# 2. 오픈소스와 상용 LLM

## 목차 📑

### 1. LLM 유형 비교 🤖
- [1.1 오픈소스 LLM](#오픈소스-llm)
- [1.2 상용 LLM](#상용-llm)

### 2. LLM 성능 리더보드 🏆
- [2.1 주요 벤치마크 및 리더보드](#주요-벤치마크-및-리더보드)


## LLM 유형 비교 🤖

### 오픈소스 LLM

#### 설명

**오픈소스 LLM**은 모델의 파라미터가 공개되어 누구나 추가 학습이나 추론에 활용할 수 있다. 대표적으로 **LLaMA, MPT, Alpaca, Vicuna, Falcon** 등이 있다. 일반적으로 무료로 사용할 수 있지만, 인퍼런스 파이프라인을 직접 구축해야 하며, 상업적 이용 시 라이선스 확인이 필요하다.

#### 예시

```python
# 오픈소스 LLM 예시 (HuggingFace Transformers 활용)
from transformers import AutoModelForCausalLM, AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("mosaicml/mpt-7b")
model = AutoModelForCausalLM.from_pretrained("mosaicml/mpt-7b")

input_text = "가을 저녁 산책에 어울리는 옷차림을 추천해줘."
inputs = tokenizer(input_text, return_tensors="pt")
outputs = model.generate(**inputs, max_length=50)
print(tokenizer.decode(outputs[0]))
```

#### 주의사항

- **상업적 사용** 전에는 반드시 라이선스 조항을 확인해야 한다.
- 직접 인퍼런스 서버를 운영할 경우, **서버 비용**이 발생할 수 있다.

---

### 상용 LLM

#### 설명

**상용 LLM**은 모델 파라미터를 공개하지 않고, **API 엔드포인트**를 통해 접근한다. 대표적으로 **ChatGPT(OpenAI), Claude(Anthropic), Bard(Google)** 등이 있다. 사용량에 따라 비용이 발생하지만, 인프라 관리가 필요 없고, 클라우드 인프라의 이점을 누릴 수 있다. 일반적으로 오픈소스 모델보다 성능이 우수하다.

#### 예시

```python
# 상용 LLM API 예시 (OpenAI)
import openai

def get_ai_suggestion(prompt):
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "당신은 패션 코디 전문가입니다."},
            {"role": "user", "content": prompt}
        ]
    )
    return response['choices'][0]['message']['content']

result = get_ai_suggestion("봄 소풍에 어울리는 옷차림을 추천해줘.")
print(result)
```

#### 주의사항

- **API 사용량**에 따라 비용이 발생하므로, 예산을 고려하여 사용해야 한다.
- 각 서비스의 **Context Length**(입력/출력 토큰 한도)와 가격 정책을 확인해야 한다.

---

## LLM 성능 리더보드 🏆

### 주요 벤치마크 및 리더보드

#### 설명

LLM의 성능은 다양한 **벤치마크**(예: Chatbot Arena, MT Bench, MMLU 등)를 통해 평가된다. 대표적인 리더보드로는 HuggingFace Open LLM Leaderboard, LMSYS Chatbot Arena 등이 있다. 주요 평가지표는 **Elo 점수, 멀티태스크 정확도, 대화 품질** 등이다.

| 모델명                | Arena Elo | MMLU (%) | SWE-bench (%) | 라이선스      |
|----------------------|-----------|----------|---------------|--------------|
| Gemini 2.5 Pro       | 1463      | 89.8     | 63.8          | Proprietary  |
| OpenAI o3-2025-04-16 | 1449      | 84.0     | 49.3          | Proprietary  |
| GPT-4o (2025-03-26)  | 1441      | -        | -             | Proprietary  |
| GPT-4.5 Preview      | 1436      | -        | -             | Proprietary  |
| Claude Opus 4        | 1417      | 88.8     | 79.4          | Proprietary  |
| Gemini 2.5 Flash     | 1415      | -        | -             | Proprietary  |
| DeepSeek R1          | 1413      | 71.5     | 49.2          | Apache 2.0   |
| GPT-4.1 (2025-04-14) | 1411      | 79.2     | 52.0          | Proprietary  |
| Grok 3 Preview       | 1408      | 80.2     | -             | Proprietary  |
| Claude Sonnet 4      | 1382      | 86.5     | 80.2          | Proprietary  |


#### 예시

```python
# 리더보드 정보 조회 예시 (웹 크롤링)
import requests
from bs4 import BeautifulSoup

url = "https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard"
response = requests.get(url)
soup = BeautifulSoup(response.text, "html.parser")
# 실제 데이터 파싱 로직은 생략
```

#### 주의사항

- 벤치마크 점수는 **업데이트 시점**과 **평가 기준**에 따라 달라질 수 있다.
- 실제 애플리케이션 목적에 맞는 **성능 지표**를 우선적으로 고려해야 한다.

