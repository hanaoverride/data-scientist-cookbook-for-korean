# 1. 생성형 AI를 활용한 애플리케이션 개발

## 목차 📑

### 1. 생성 AI 활용 프로세스 개요
- [1.1 과정 개요](#과정-개요-) 📝
- [1.2 사용자 입력과 생성 AI 출력](#사용자-입력과-생성-ai-출력-) 🔄

### 2. 세부 기능 정의
- [2.1 LLM과 서비스 특화](#llm과-서비스-특화-) 🛠️
- [2.2 프롬프트 엔지니어링의 실제](#프롬프트-엔지니어링의-실제-) 🧩
- [2.3 파이프라인 설계](#파이프라인-설계-) 🔗

### 3. UI 구현
- [3.1 UI의 역할과 팀 구성](#ui의-역할과-팀-구성-) 🖥️
- [3.2 UI 디자인 패턴](#ui-디자인-패턴-) 🎨
- [3.3 주요 프레임워크](#주요-프레임워크-) 🛠️

### 4. 프롬프트 엔지니어링을 통한 결과 확인
- [4.1 피드백 루프와 개선](#피드백-루프와-개선-) 🔁
- [4.2 프롬프트 작성 예시](#프롬프트-작성-예시-) ✍️

### 5. 결과 평가, 개선 및 유지보수
- [5.1 생성 AI 결과 평가](#생성-ai-결과-평가-) 🏅
- [5.2 GPT 기반 평가 방법](#gpt-기반-평가-방법-) 🤖
- [5.3 지속적 개선과 유지보수](#지속적-개선과-유지보수-) 🔄

---

## 과정 개요 📝

생성 AI를 활용한 애플리케이션 개발은 **사용자 입력**을 받아 **AI 모델**을 통해 결과를 생성하고, 이를 **서비스 목적**에 맞게 가공하여 제공하는 일련의 과정을 의미한다. 요즘에 들어서는 Vibe Coding이라는 용어로도 불린다. 

> **Vibe Coding**이란?: Vibe라는 인터넷 신조어는 '기분'이나 '분위기'를 의미하며, 사용자의 감정이나 상황에 맞춰 AI가 적절한 출력을 생성하는 것을 강조한다. Vibe Coding은 이렇듯 Vibe에 맞춰 코딩한다는 의미에서 지어진 이름이다. 프롬프트를 지속적으로 개선해 개발하는 과정이 특징으로, 최근에는 Cursor AI나 Github Copilot Agent, Claude Code, Gemini CLI 등의 도구가 주목받고 있다.

이 과정은 다음과 같은 단계로 구성된다:

1. **사용자 입력과 생성 AI 출력**의 이해
2. **세부 기능 정의** 및 프롬프트 설계
3. **UI 구현**을 통한 사용자 경험 제공
4. **프롬프트 엔지니어링**을 통한 결과 확인 및 개선
5. **결과 평가와 유지보수**를 통한 서비스 품질 관리

---

## 사용자 입력과 생성 AI 출력 🔄

### 설명

**생성 AI**는 주로 **자연어 인터페이스**를 통해 사용자와 상호작용한다. 사용자는 자연어로 정보를 입력하며, AI는 목적에 따라 다양한 형태(텍스트, 이미지, 오디오 등)로 출력을 반환한다. 최근에는 **거대 언어 모델(LLM)** 과 **이미지 생성 모델(DM)** 이 널리 활용되고 있으며, 챗봇, 번역, 요약, 이미지 생성 등 다양한 서비스에 적용된다.

### 예시

```python
# 자연어 입력을 받아 실제 이미지 생성 모델을 호출하는 예시 (예: OpenAI DALL·E API 사용)
import openai

user_prompt = "노을이 지는 바닷가 풍경을 그려줘"

# 실제 API 호출 (API 키는 환경 변수 등으로 안전하게 관리)
response = openai.Image.create(
    prompt=user_prompt,
    n=1,
    size="512x512"
)
generated_image_url = response['data'][0]['url']
print(f"생성된 이미지 URL: {generated_image_url}")
```

### 주의사항

- 멀티모달 LLM의 발달에 따라 입력과 출력이 반드시 자연어 텍스트 형태가 아닐 수 있다.
- **프롬프트의 명확성**이 결과 품질에 큰 영향을 미친다.

---

## LLM과 서비스 특화 🛠️

### 설명

과거의 AI 모델은 특정 태스크에 특화된 전문가 모델이 주류였으나, 최근에는 **Foundation Model**(예: GPT 계열) 하나로 다양한 문제를 해결하는 방식이 일반화되었다. **프롬프트**는 언어 모델에 입력하는 정보로, 이를 통해 하나의 모델로 여러 서비스 목적에 맞는 결과를 얻을 수 있다.

### 예시
```python
# 실제 LLM API를 호출해 여러 리뷰를 분류하는 현실적인 예시 (예: OpenAI GPT API 사용)
import openai

reviews = [
    "배송이 빨라서 좋았어요.",
    "상품이 사진과 달라서 실망했습니다.",
    "가격 대비 무난한 제품입니다."
]

classified = []
for review in reviews:
    prompt = f"다음 리뷰의 감정을 긍정, 부정, 중립 중 하나로 분류해줘:\n리뷰: \"{review}\""
    response = openai.chat.completions.create(
        model="gpt-4.1-mini",
        messages=[{"role": "user", "content": prompt}],
        max_tokens=10
    )
    label = response.choices[0].message.content.strip()
    classified.append(label)

for review, label in zip(reviews, classified):
    print(f"리뷰: '{review}' → 분류 결과: {label}")
```

### 주의사항

- **프롬프트 엔지니어링** 없이 단순 입력만 제공하면 원하는 결과를 얻기 어렵다.
- 서비스 목적에 맞는 **구체적이고 명확한 프롬프트**가 필요하다.

---

## 프롬프트 엔지니어링의 실제 🧩

### 설명

**프롬프트 엔지니어링**을 통해 LLM의 출력을 서비스 목적에 맞게 세밀하게 조정할 수 있다. 입출력 예시, 출력 포맷(예: 마크다운, JSON) 등을 프롬프트에 포함시키면 더욱 일관된 결과를 얻을 수 있다. 

최근의 언어 모델들은 이를 구조화된 출력(structured output)이라는 기능으로 언어의 클래스 구조를 참조하도록 지원한다.

배치 작업을 통해 여러 개의 프롬프트를 동시에 처리할 경우 처리 속도가 높아지며, 인덱스를 부착함으로서 프롬프트의 결과 누락을 줄일 수 있다.

### 예시

```python
# 출력 포맷을 명시한 프롬프트 예시
prompt = (
    "아래 정보를 표 형태의 마크다운으로 정리해줘.\n"
    "이름: 김하늘, 나이: 29, 직업: 디자이너"
)
# 실제 LLM 호출은 생략
output = """
| 이름   | 나이 | 직업     |
|--------|------|----------|
| 김하늘 | 29   | 디자이너 |
"""
print(output)
```

### 주의사항

- **출력 포맷**을 명확히 지정하지 않으면 결과가 일관되지 않을 수 있다.
- **입출력 예시**를 포함하면 모델의 응답 품질이 향상된다.

---

## 파이프라인 설계 🔗

### 설명

복잡한 AI 서비스는 여러 모델의 결과를 조합하거나, 단계별로 처리하는 **파이프라인 구조**를 갖는다. 예를 들어, 이미지에서 객체를 검출한 뒤 해당 영역을 검색하고, 마지막으로 언어 모델을 통해 최종 결과를 생성하는 방식이 있다.

### 예시

PDF를 OCR하여 텍스트를 추출한 뒤, 교정하여 검색 가능한 PDF를 만드는 파이프라인의 예시

1. EasyOCR로 PDF의 이미지를 텍스트로 변환, json 포맷으로 저장
2. LLM을 호출하여 교정
3. 교정된 텍스트를 기반으로 검색 가능한 PDF 생성 오버레이

[PDF-OCR-by-LLM](https://github.com/hanaoverride/PDF-OCR-by-LLM)


### 주의사항

- **여러 모델의 입출력 구조**를 명확히 설계해야 한다.
- 각 단계의 결과가 다음 단계의 입력으로 자연스럽게 연결되어야 한다.

---

## UI의 역할과 팀 구성 🖥️

### 설명

**UI(User Interface)** 는 사용자가 값을 입력하고 출력을 확인하는 방식의 디자인을 의미한다. 효율성뿐만 아니라 **직관성**과 **심미성**도 중요하다. 실제 AI 서비스 개발에서는 **AI 모델링, 백엔드, 프론트엔드** 등 다양한 역할이 분업된다.

### 예시

```python
# Gradio를 활용한 간단한 텍스트 생성 데모 예시
import gradio as gr

def generate_text(prompt):
    return f"입력하신 내용: {prompt}"

demo = gr.Interface(fn=generate_text, inputs="text", outputs="text")
demo.launch()
```

### 주의사항

- 한 명의 엔지니어가 전체 파이프라인을 모두 담당하기는 어렵다.

---

## UI 디자인 패턴 🎨

### 설명

UI 디자인에는 **스큐어모피즘**(사실적 3D 스타일)과 **플랫 디자인**(단순 2D 스타일) 등 다양한 패턴이 있다. 스큐어모피즘은 디지털 환경에 익숙하지 않은 사용자에게 친숙함을 주고, 플랫 디자인은 가독성과 속도 면에서 장점이 있다.

### 예시

| 디자인 패턴     | 특징                        |
|----------------|----------------------------|
| 스큐어모피즘   | 3D 효과, 사실적, 친근함     |
| 플랫 디자인    | 2D, 단순, 빠른 로딩, 가독성 |

### 주의사항

- 서비스 대상 사용자에 따라 적합한 디자인 패턴을 선택해야 한다.

---

## 주요 프레임워크 🛠️

### 설명

AI 및 데이터 기반 웹 애플리케이션 개발에는 다양한 프레임워크가 활용된다.

- **Gradio**: 최소한의 코드로 AI 모델을 GUI에서 테스트할 수 있는 프레임워크로, 챗봇, 피드백 등 인터페이스 구현에 적합하다.
- **Streamlit**: 파이썬 기반 데이터 웹앱 제작에 특화되어 있으며, 데이터 분석 및 AI 데모에 널리 사용된다.
- **HTML/CSS/JavaScript**: 웹 개발의 기본 기술로, 각각 구조, 스타일, 동작을 담당한다.

### 예시

```python
# Streamlit을 활용한 간단한 데이터 앱 예시
import streamlit as st

st.title("간단한 데이터 입력 앱")
name = st.text_input("이름을 입력하세요:")
if name:
    st.write(f"안녕하세요, {name}님!")
```

### 주의사항

- **Gradio**와 **Streamlit**은 빠른 프로토타이핑에 적합하나, 대규모 서비스에는 별도의 프론트엔드 개발이 필요할 수 있다.

---

## 피드백 루프와 개선 🔁

### 설명

AI 모델 및 프롬프트 엔지니어링은 **반복적(iterative) 개선 과정**을 통해 성능을 높인다. 최초 모델 학습, 성능 평가, 단점 보완의 사이클을 반복하며, **평가지표**와 **보완책**의 수립이 중요하다.

### 예시

```python
# 프롬프트 개선을 위한 반복적 실험 예시
prompts = [
    "날씨에 어울리는 옷을 추천해줘.",
    "20대 여성을 위한 가을 저녁 데이트룩을 추천해줘. 표로 정리해줘."
]
for prompt in prompts:
    # 실제 LLM 호출은 생략
    print(f"프롬프트: {prompt}\n결과: ...\n")
```

### 주의사항

- **완벽한 프롬프트**는 존재하지 않으므로, 지속적인 평가와 개선이 필요하다.
- **In-context Learning**을 활용하여 예시 기반 개선이 가능하다.

---

## 프롬프트 작성 예시 ✍️

### 설명

LLM은 **구체적이고 명확한 정보**가 주어질수록 더 적절한 답변을 생성한다. 필요에 따라 **입출력 예시**를 포함시키면 원하는 결과를 세밀하게 조정할 수 있다.

### 예시

```python
# 구체적 조건을 포함한 프롬프트 예시
prompt = (
    "10월 저녁, 캐주얼한 분위기의 레스토랑에서 소개팅을 할 때 입을 옷을 추천해줘. "
    "성별: 남성, 나이: 20대 후반, 장소: 루프탑 레스토랑, 표로 정리해줘."
)
# 실제 LLM 호출은 생략
output = """
| 아이템       | 추천 스타일          |
|--------------|---------------------|
| 상의         | 체크 셔츠 + 니트    |
| 하의         | 슬림핏 청바지       |
| 아우터       | 가벼운 재킷         |
| 신발         | 로퍼                |
"""
print(output)
```

### 주의사항

- **프롬프트가 구체적일수록** 결과의 품질이 높아진다.
- **출력 형식**을 명확히 지정해야 일관된 결과를 얻을 수 있다.

---

## 생성 AI 결과 평가 🏅

### 설명

생성 AI의 결과 평가는 **정확성, 유창성, 적절성** 등 다양한 요소를 종합적으로 고려해야 하며, 서비스 목적에 맞는 **평가지표**를 수립하는 것이 중요하다. 완벽한 평가지표가 아니더라도, 점진적 개선을 위해서는 측정 기준이 필요하다.

### 예시

| 평가 항목   | 설명                     |
|-------------|--------------------------|
| 정확성      | 사실과 일치하는가        |
| 유창성      | 자연스러운 문장 구성인가 |
| 적절성      | 맥락에 맞는가            |
| 참신성      | 새로운 정보가 있는가     |

### 주의사항

- **평가지표**는 서비스 목적에 따라 다르게 설정해야 한다.
- 측정이 어려운 경우라도, 최소한의 기준을 마련해야 개선이 가능하다.

---

## GPT 기반 평가 방법 🤖

### 설명

최근에는 **GPT-4**와 같은 LLM을 활용한 자동 평가가 널리 사용된다. 대표적으로 **비교 평가**(여러 결과 중 우수한 것 선택)와 **절대 평가**(점수 척도 부여)가 있다. 평가 기준, 점수 범위, 문제와 결과를 GPT에 입력하여 평가를 수행한다.

### 예시

```python
# GPT를 활용한 요약 평가 프롬프트 예시
evaluation_prompt = (
    "다음 뉴스 기사 요약을 1~5점 척도로 평가해줘. 평가 기준: 일관성, 정보 전달력.\n"
    "기사: 'A씨는 최근 신제품을 출시했다.'\n"
    "요약: 'A씨가 신제품을 선보였다.'"
)
# 실제 GPT 호출은 생략
score = 5  # 예시 점수
print(f"평가 점수: {score}")
```

### 주의사항

- **GPT 평가 결과**도 완벽하지 않으므로, 사람의 검토와 병행하는 것이 바람직하다.
- 평가 프롬프트의 **명확성**이 평가 신뢰도에 영향을 준다.

---

## 지속적 개선과 유지보수 🔄

### 설명

**LLM API**는 실시간으로 버전이 변경될 수 있으므로, 어제까지 잘 동작하던 입력/출력이 갑자기 달라질 수 있다. 서비스 품질 유지를 위해서는 **프롬프트의 지속적 모니터링과 개선**이 필수적이다. 지시사항의 명확성, 원치 않는 결과 방지, 추가 예시 제공 등을 꾸준히 점검해야 한다.

혹은 이러한 버전 변경을 원하지 않는다면 특정 시점의 스냅샷으로 제공된 모델을 사용하는 방법이 있다. ex(gemini-2.5-flash-preview-05-20)


### 프롬프트 개선 체크리스트

- [ ] 지시사항이 명확한가?
- [ ] 이중 해석의 소지가 없는가?
- [ ] 원치 않는 결과를 명시적으로 배제했는가?
- [ ] 추가할 만한 예시가 있는가?

### 주의사항

- **API 버전 변화**에 따라 결과가 달라질 수 있으므로, 정기적인 테스트가 필요하다.
- **프롬프트 개선**은 서비스 품질 관리의 핵심이다.